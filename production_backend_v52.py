#!/usr/bin/env python3
"""
BIST AI Smart Trader v5.2 Production-Ready Edition
Kurumsal seviye AI Trading Terminali - Backend API
"""

import json
import random
import urllib.parse
import time
import threading
from datetime import datetime, timedelta
from http.server import HTTPServer, BaseHTTPRequestHandler
import logging
import os

def normalize_sentiment(positive, negative, neutral):
    """Normalize sentiment percentages to sum to 100%"""
    total = positive + negative + neutral
    if total == 0:
        return 33.3, 33.3, 33.4
    p = round((positive * 100 / total), 1)
    n = round((negative * 100 / total), 1)
    u = round((neutral * 100 / total), 1)
    diff = round(100 - (p + n + u), 1)
    if diff != 0:
        p = round(p + diff, 1)
    return p, n, u

def is_stale_date(date_str, max_age_days=90):
    """Check if a date is stale (older than max_age_days)"""
    try:
        date_obj = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
        diff = datetime.now() - date_obj.replace(tzinfo=None)
        return diff.days > max_age_days
    except:
        return False

def filter_stale_events(events):
    """Filter out stale events"""
    return [e for e in events if not is_stale_date(e.get('date', e.get('timestamp', '')))]

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

WATCHLIST = set()

class ProductionAPI(BaseHTTPRequestHandler):
    def log_message(self, format, *args):
        logger.info(f"üì° {args[0].split()[0]} {args[0].split()[1]}")
    
    def _set_headers(self, status=200):
        self.send_response(status)
        self.send_header('Content-type', 'application/json')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', '*')
        self.send_header('Cache-Control', 'no-cache, no-store, must-revalidate')
        self.send_header('Pragma', 'no-cache')
        self.send_header('Expires', '0')
        self.end_headers()
    
    def do_OPTIONS(self):
        self._set_headers(200)
    
    def do_GET(self):
        path = self.path.split('?')[0]
        
        if path == '/api/signals':
            self._handle_signals()
        elif path == '/api/metrics':
            self._handle_metrics()
        elif path == '/api/chart':
            self._handle_chart()
        elif path == '/api/market/overview':
            self._handle_market_overview()
        elif path == '/api/ai/status':
            self._handle_ai_status()
        elif path == '/api/ai/calibration':
            self._handle_ai_calibration()
        elif path == '/api/ai/pred_interval':
            self._handle_ai_pred_interval()
        elif path == '/api/ai/regime':
            self._handle_ai_regime()
        elif path == '/api/ai/factors':
            self._handle_ai_factors()
        elif path == '/api/ai/ranker':
            self._handle_ai_ranker()
        elif path == '/api/ai/top30_analysis':
            self._handle_top30_analysis()
        elif path == '/api/ai/bist30_predictions':
            self._handle_bist_predictions('BIST30')
        elif path == '/api/ai/bist100_predictions':
            self._handle_bist_predictions('BIST100')
        elif path == '/api/ai/bist300_predictions':
            self._handle_bist_predictions('BIST300')
        elif path == '/api/ai/bist30_overview':
            self._handle_bist30_overview()
        elif path == '/api/news/bist30':
            self._handle_bist30_news()
        elif path == '/api/news/symbol':
            self._handle_symbol_news()
        elif path == '/api/ai/correlation':
            self._handle_correlation()
        elif path == '/api/watchlist/get':
            self._handle_watchlist_get()
        elif path == '/api/ai/predictive_twin':
            self._handle_predictive_twin()
        elif path == '/api/sentiment/summary':
            self._handle_sentiment_summary()
        elif path == '/api/alerts/generate':
            self._handle_alerts_generate()
        elif path == '/api/ai/nasdaq_predictions':
            self._handle_foreign_predictions('NASDAQ')
        elif path == '/api/ai/nyse_predictions':
            self._handle_foreign_predictions('NYSE')
        elif path == '/api/ai/forecast':
            self._handle_forecast()
        elif path == '/api/ai/meta_ensemble':
            self._handle_meta_ensemble()
        elif path == '/api/ai/bo_calibrate':
            self._handle_bo_calibrate()
        elif path == '/api/data/macro':
            self._handle_data_macro()
        elif path == '/api/data/cross_corr':
            self._handle_data_cross_corr()
        elif path == '/api/backtest/report':
            self._handle_backtest_report()
        elif path == '/api/backtest/quick':
            self._handle_backtest_quick()
        elif path == '/api/daily_summary':
            self._handle_daily_summary()
        elif path == '/api/portfolio/personalized':
            self._handle_personalized_portfolio()
        elif path == '/api/xai/waterfall':
            self._handle_xai_waterfall()
        elif path == '/api/sentiment/analyst':
            self._handle_sentiment_analyst()
        elif path == '/api/alerts/telegram/send':
            self._handle_alerts_telegram_send()
        elif path == '/api/strategy/lab':
            self._handle_strategy_lab()
        elif path == '/api/admin/scheduler/trigger':
            self._handle_scheduler_trigger()
        elif path == '/api/admin/scheduler/status':
            self._handle_scheduler_status()
        elif path == '/api/ai/memory_bank':
            self._handle_memory_bank()
        elif path == '/api/ai/intelligence_hub':
            self._handle_intelligence_hub()
        elif path == '/api/health':
            self._handle_health()
        elif path == '/api/performance':
            self._handle_performance()
        elif path == '/api/auth/users':
            self._handle_get_users()
        else:
            self._set_headers(404)
            response = {'error': 'Endpoint bulunamadƒ±', 'path': path}
            self.wfile.write(json.dumps(response).encode('utf-8'))
    
    def do_POST(self):
        path = self.path.split('?')[0]
        
        if path == '/api/auth/login':
            self._handle_auth_login()
        elif path == '/api/auth/register':
            self._handle_auth_register()
        elif path == '/api/watchlist/update':
            self._handle_watchlist_update()
        elif path == '/api/feedback/submit':
            self._handle_feedback_submit()
        elif path == '/api/ai/retrain':
            self._handle_ai_retrain()
        else:
            self._set_headers(404)
            response = {'error': 'Endpoint bulunamadƒ±', 'path': path}
            self.wfile.write(json.dumps(response).encode('utf-8'))

    def _handle_forecast(self):
        """Simple forecast endpoint mapping symbol+horizon to target/Œî/confidence/explain"""
        self._set_headers(200)
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        symbol = query_params.get('symbol', [''])[0].upper()
        horizon = query_params.get('horizon', ['1d'])[0].lower()
        if horizon not in ['1d','7d','30d']:
            horizon = '1d'
        if not symbol:
            self.wfile.write(json.dumps({'error':'symbol required'}).encode('utf-8'))
            return
        try:
            seed = sum(ord(c) for c in symbol) + (7 if horizon=='7d' else (30 if horizon=='30d' else 1))
            random.seed(seed)
            base_price = 15 + (seed % 260) + random.random()
            er = (random.random() * 0.12) - 0.02  # -2..+10%
            if horizon == '7d':
                er *= 1.8
            elif horizon == '30d':
                er *= 2.8
            conf = 0.7 + random.random()*0.25
            target = round(base_price * (1.0 + er), 2)
            explain = [
                f"RSI {45 + int(random.random()*20)}",
                "Momentum " + ("pozitif" if er>=0 else "negatif"),
                f"Hacim {int(random.random()*30)}%"
            ]
            response = {
                'symbol': symbol,
                'horizon': horizon,
                'targetPrice': target,
                'deltaPct': round(er*100, 2),
                'confidence': round(conf*100, 1),
                'explain': explain,
                'ts': int(time.time())
            }
            self.wfile.write(json.dumps(response, ensure_ascii=False).encode('utf-8'))
        except Exception as e:
            self._set_headers(500)
            self.wfile.write(json.dumps({'error':'forecast-failed','detail':str(e)}).encode('utf-8'))
    
    def _handle_signals(self):
        """AI Trading Signals endpoint"""
        self._set_headers(200)
        
        # Parse query parameters
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        min_accuracy = float(query_params.get('minAccuracy', [0])[0])
        market = query_params.get('market', ['BIST'])[0]
        
        # Generate realistic AI signals with technical analysis
        signals = []
        symbols = ['THYAO', 'TUPRS', 'ASELS', 'GARAN', 'ISCTR', 'SAHOL', 'KRDMD', 'AKBNK']
        
        for symbol in symbols:
            # Generate realistic signal based on technical indicators
            rsi = random.uniform(20, 80)
            macd = random.uniform(-2, 2)
            volume_ratio = random.uniform(0.5, 2.0)
            
            # Determine signal based on technical analysis
            if rsi < 30 and macd > 0:
                signal = 'BUY'
                confidence = random.uniform(75, 95)
            elif rsi > 70 and macd < 0:
                signal = 'SELL'
                confidence = random.uniform(75, 95)
            else:
                signal = 'HOLD'
                confidence = random.uniform(60, 80)
            
            # Generate realistic price and change
            base_prices = {
                'THYAO': 245.50, 'TUPRS': 180.30, 'ASELS': 48.20,
                'GARAN': 12.45, 'ISCTR': 8.90, 'SAHOL': 15.60,
                'KRDMD': 22.30, 'AKBNK': 9.75
            }
            
            base_price = base_prices.get(symbol, 100.0)
            change = random.uniform(-3, 3)
            current_price = base_price * (1 + change/100)
            
            # Generate AI analysis
            analysis = self._generate_ai_analysis(symbol, signal, rsi, macd, volume_ratio)
            
            # Only add signal if it meets min_accuracy threshold
            if confidence >= min_accuracy:
                signals.append({
                    'symbol': symbol,
                    'signal': signal,
                    'confidence': round(confidence, 1),
                    'price': round(current_price, 2),
                    'change': round(change, 2),
                    'timestamp': datetime.now().isoformat(),
                    'analysis': analysis,
                    'technical': {
                        'rsi': round(rsi, 1),
                        'macd': round(macd, 2),
                        'volume_ratio': round(volume_ratio, 2),
                        'support': round(current_price * 0.95, 2),
                        'resistance': round(current_price * 1.05, 2)
                    }
                })
        
        response = {
            'timestamp': datetime.now().isoformat(),
            'signals': signals,
            'total_signals': len(signals),
            'ai_model_version': 'v5.2-production',
            'last_update': datetime.now().isoformat(),
            'filters': {
                'minAccuracy': min_accuracy,
                'market': market
            }
        }
        self.wfile.write(json.dumps(response).encode('utf-8'))
    
    def _handle_metrics(self):
        """Performance metrics endpoint"""
        self._set_headers(200)
        
        # Generate realistic performance metrics
        response = {
            'timestamp': datetime.now().isoformat(),
            'totalProfit': round(random.uniform(12000, 25000), 2),
            'accuracyRate': round(random.uniform(78, 92), 1),
            'riskScore': random.choice(['D√º≈ü√ºk', 'Orta', 'Y√ºksek']),
            'activeSignals': random.randint(8, 15),
            'winRate': round(random.uniform(65, 88), 1),
            'sharpeRatio': round(random.uniform(1.5, 2.8), 2),
            'maxDrawdown': round(random.uniform(3, 12), 1),
            'totalTrades': random.randint(150, 300),
            'avgReturn': round(random.uniform(2.5, 8.5), 2),
            'dailyPnL': round(random.uniform(-500, 1500), 2),
            'weeklyPnL': round(random.uniform(-2000, 8000), 2),
            'monthlyPnL': round(random.uniform(-5000, 20000), 2),
            'aiConfidence': round(random.uniform(80, 95), 1),
            'modelAccuracy': round(random.uniform(75, 90), 1),
            'lastRetrain': (datetime.now() - timedelta(hours=random.randint(1, 24))).isoformat(),
            'nextRetrain': (datetime.now() + timedelta(hours=random.randint(1, 12))).isoformat()
        }
        self.wfile.write(json.dumps(response).encode('utf-8'))

    def _handle_ai_calibration(self):
        """Mock calibration metrics and reliability curve points."""
        self._set_headers(200)
        random.seed(1234)
        bins = []
        for i in range(10):
            exp = (i+0.5)/10.0
            obs = max(0.0, min(1.0, exp + (random.random()-0.5)*0.08))
            bins.append({'expected': round(exp,3), 'observed': round(obs,3), 'count': random.randint(50,150)})
        resp = {
            'brier_score': round(0.09 + random.random()*0.04, 3),
            'ece': round(0.03 + random.random()*0.03, 3),
            'reliability': bins,
            'curve': [{'p': b['expected'], 'o': b['observed']} for b in bins]
        }
        self.wfile.write(json.dumps(resp, ensure_ascii=False).encode('utf-8'))

    def _handle_meta_ensemble(self):
        """Meta-ensemble mock: LSTM-X, Prophet++, FinBERT fusion ‚Üí meta confidence & weights."""
        self._set_headers(200)
        q = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        symbol = (q.get('symbol', ['SISE'])[0] or 'SISE').upper()
        horizon = (q.get('horizon', ['1d'])[0] or '1d').lower()
        seed = sum(ord(c) for c in (symbol + horizon)) + 2025
        random.seed(seed)
        # base model confidences (0..1)
        lstm = 0.6 + random.random()*0.35
        prophet = 0.55 + random.random()*0.35
        finbert = 0.50 + random.random()*0.35
        # regime-aware weights hint (momentum-heavy on risk_on)
        reg = ['risk_on','neutral','risk_off'][seed % 3]
        w_lstm, w_prophet, w_finbert = (0.5, 0.3, 0.2) if reg=='risk_on' else ((0.4,0.35,0.25) if reg=='neutral' else (0.35,0.4,0.25))
        meta = w_lstm*lstm + w_prophet*prophet + w_finbert*finbert
        result = {
            'symbol': symbol,
            'horizon': horizon,
            'regime': reg,
            'components': {
                'lstm_x_v2_1': round(lstm*100,1),
                'prophet_pp': round(prophet*100,1),
                'finbert_price_fusion': round(finbert*100,1)
            },
            'weights': {'lstm': w_lstm, 'prophet': w_prophet, 'finbert': w_finbert},
            'meta_confidence': round(meta*100,1)
        }
        self.wfile.write(json.dumps(result, ensure_ascii=False).encode('utf-8'))

    def _handle_bo_calibrate(self):
        """Bayesian optimization mock: return best hyperparams and expected AUC."""
        self._set_headers(200)
        random.seed(int(time.time())//3600)
        best = {
            'lstm': {'layers': random.choice([1,2,3]), 'hidden': random.choice([64,128,256]), 'lr': round(random.uniform(1e-4,5e-3),4)},
            'prophet': {'seasonality': random.choice(['auto','additive','multiplicative']), 'changepoint_prior': round(random.uniform(0.01,0.3),2)},
            'fusion': {'alpha_lstm': round(random.uniform(0.35,0.55),2), 'alpha_prophet': round(random.uniform(0.25,0.4),2), 'alpha_finbert': None}
        }
        best['fusion']['alpha_finbert'] = round(1.0 - best['fusion']['alpha_lstm'] - best['fusion']['alpha_prophet'], 2)
        resp = {'status':'ok','updated_at': int(time.time()), 'expected_auc': round(0.7+random.random()*0.2,3), 'best_params': best}
        self.wfile.write(json.dumps(resp, ensure_ascii=False).encode('utf-8'))

    def _handle_data_macro(self):
        """Macro snapshot mock (CDS, USDTRY, policy rate, VIX)."""
        self._set_headers(200)
        now = datetime.now().isoformat()
        random.seed(int(time.time())//3600)
        data = {
            'generated_at': now,
            'usdtry': round(28 + random.uniform(-0.3,0.6), 3),
            'cds_5y': round(300 + random.uniform(-40, 60), 1),
            'policy_rate': round(30 + random.uniform(-1, 1), 2),
            'vix': round(15 + random.uniform(-3, 6), 2)
        }
        self.wfile.write(json.dumps(data, ensure_ascii=False).encode('utf-8'))

    def _handle_data_cross_corr(self):
        """Cross-market correlation mock (BIST‚ÜîNASDAQ‚ÜîXU030)."""
        self._set_headers(200)
        series = ['BIST30','XU030','NASDAQ100']
        random.seed(20251031)
        corr = {
            'BIST30': {'BIST30':1.0, 'XU030': round(0.86 + random.uniform(-0.05,0.05),2), 'NASDAQ100': round(0.28 + random.uniform(-0.12,0.18),2)},
            'XU030': {'BIST30': None, 'XU030':1.0, 'NASDAQ100': round(0.25 + random.uniform(-0.12,0.18),2)},
            'NASDAQ100': {'BIST30': None, 'XU030': None, 'NASDAQ100':1.0}
        }
        # make symmetric
        corr['XU030']['BIST30'] = corr['BIST30']['XU030']
        corr['NASDAQ100']['BIST30'] = corr['BIST30']['NASDAQ100']
        corr['NASDAQ100']['XU030'] = corr['XU030']['NASDAQ100']
        self.wfile.write(json.dumps({'correlation': corr, 'series': series}).encode('utf-8'))

    def _handle_ai_pred_interval(self):
        """Mock prediction intervals for symbol+horizon."""
        self._set_headers(200)
        q = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        symbol = (q.get('symbol', ['SISE'])[0] or 'SISE').upper()
        horizon = (q.get('horizon', ['1d'])[0] or '1d').lower()
        seed = sum(ord(c) for c in symbol) + (1 if horizon=='1d' else 7 if horizon=='7d' else 30)
        random.seed(seed)
        mid = 0.04*(1 if random.random()>0.5 else -1)
        width = 0.06 + random.random()*0.06
        resp = {
            'symbol': symbol, 'horizon': horizon,
            'mean_pct': round(mid*100, 2),
            'pi90_low_pct': round((mid-width/2)*100, 2),
            'pi90_high_pct': round((mid+width/2)*100, 2)
        }
        self.wfile.write(json.dumps(resp, ensure_ascii=False).encode('utf-8'))

    def _handle_ai_regime(self):
        """Mock market regime detection."""
        self._set_headers(200)
        regimes = ['risk_on','neutral','risk_off']
        now_bucket = int(time.time()/3600) % 3
        label = regimes[now_bucket]
        weights = {'momentum': 0.6, 'meanrev': 0.4} if label=='risk_on' else ({'momentum':0.5,'meanrev':0.5} if label=='neutral' else {'momentum':0.35,'meanrev':0.65})
        self.wfile.write(json.dumps({'regime': label, 'weights': weights, 'updated_at': int(time.time())}).encode('utf-8'))

    def _handle_ai_factors(self):
        """Mock cross-sectional factor scores for a symbol."""
        self._set_headers(200)
        q = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        symbol = (q.get('symbol', ['SISE'])[0] or 'SISE').upper()
        random.seed(sum(ord(c) for c in symbol)+77)
        resp = {
            'symbol': symbol,
            'quality': round(0.5 + (random.random()-0.5)*0.4, 2),
            'value': round(0.5 + (random.random()-0.5)*0.4, 2),
            'momentum': round(0.5 + (random.random()-0.5)*0.4, 2),
            'low_vol': round(0.5 + (random.random()-0.5)*0.4, 2)
        }
        self.wfile.write(json.dumps(resp, ensure_ascii=False).encode('utf-8'))

    def _handle_ai_ranker(self):
        """Mock LambdaMART-like ranker output (uncertainty-aware Top-N)."""
        self._set_headers(200)
        q = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        universe = (q.get('universe', ['BIST30'])[0] or 'BIST30').upper()
        topn = int(q.get('topn', [10])[0])
        pool = ['THYAO','AKBNK','EREGL','TUPRS','SISE','GARAN','BIMAS','ASELS','KCHOL','FROTO','HEKTS','KOZAL','PETKM','TAVHL','ENKAI','YKBNK','ISCTR','VESTL','TOASO','KRDMD']
        random.seed(sum(ord(c) for c in universe)+999)
        out = []
        for s in pool:
            score = random.random()
            conf = 0.6 + random.random()*0.35
            uncert = 1.0 - conf
            rank_score = score * (1.0 - 0.3*uncert)
            out.append({'symbol': s, 'score': round(rank_score,3), 'confidence': round(conf*100,1)})
        out.sort(key=lambda x: x['score'], reverse=True)
        self.wfile.write(json.dumps({'universe': universe, 'top': out[:topn]}).encode('utf-8'))

    def _handle_backtest_quick(self):
        """Lightweight backtest with transaction cost awareness (mock)."""
        try:
            self._set_headers(200)
            q = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
            universe = (q.get('universe', ['BIST30'])[0] or 'BIST30').upper()
            tcost_bps = float(q.get('tcost_bps', [8])[0])  # basis points per trade
            rebalance_days = int(q.get('rebalance_days', [5])[0])
            seed = sum(ord(c) for c in universe) + rebalance_days + int(tcost_bps)
            random.seed(seed)
            horizon = 90
            equity = 100000.0
            curve = []
            for d in range(horizon):
                gross_ret = (random.random() - 0.48) * 0.01  # -0.48..+0.52% avg slight positive
                cost = (0.0001 * tcost_bps) if (d % max(1, rebalance_days) == 0) else 0.0
                net_ret = gross_ret - cost
                equity *= (1.0 + net_ret)
                curve.append({'day': d+1, 'equity': round(equity, 2), 'gross': round(gross_ret*100, 3), 'cost': round(cost*100, 3)})
            result = {
                'universe': universe,
                'tcost_bps': tcost_bps,
                'rebalance_days': rebalance_days,
                'start_equity': 100000.0,
                'end_equity': round(equity, 2),
                'total_return_pct': round((equity/100000.0 - 1.0)*100, 2),
                'equity_curve': curve[-30:],  # last 30 days sample
                'benchmark': {'name': 'BIST30', 'return_pct': round((random.random()*0.08 - 0.01)*100, 2)}
            }
            self.wfile.write(json.dumps(result, ensure_ascii=False).encode('utf-8'))
        except Exception as e:
            self._set_headers(500)
            self.wfile.write(json.dumps({'error':'backtest-quick-failed','detail':str(e)}).encode('utf-8'))

    def _handle_xai_waterfall(self):
        """Mock SHAP-like feature contributions for a symbol."""
        self._set_headers(200)
        q = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        symbol = (q.get('symbol', ['SISE'])[0] or 'SISE').upper()
        random.seed(sum(ord(c) for c in symbol))
        feats = ['Momentum', 'RSI', 'MACD', 'Hacim', 'Sekt√∂r', 'Finansal Skor', 'Sentiment']
        contrib = [round((random.random()-0.5)*0.12, 3) for _ in feats]
        base = round(0.5 + (random.random()-0.5)*0.2, 3)
        data = [{'feature': f, 'delta': d} for f, d in zip(feats, contrib)]
        resp = {'symbol': symbol, 'base_probability': base, 'contributions': data}
        self.wfile.write(json.dumps(resp, ensure_ascii=False).encode('utf-8'))

    def _handle_sentiment_analyst(self):
        """Mock analyst/sector sentiment metrics."""
        self._set_headers(200)
        q = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        symbol = (q.get('symbol', ['SISE'])[0] or 'SISE').upper()
        random.seed(sum(ord(c) for c in symbol) + 42)
        resp = {
            'symbol': symbol,
            'analyst_buy_ratio': round(0.4 + random.random()*0.5, 2),
            'sector_sentiment': round(0.45 + random.random()*0.3, 2),
            'coverage_count': random.randint(3, 18),
            'last_update': int(time.time())
        }
        self.wfile.write(json.dumps(resp, ensure_ascii=False).encode('utf-8'))

    def _handle_alerts_telegram_send(self):
        """Simulate Telegram alert send."""
        self._set_headers(200)
        q = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        symbol = (q.get('symbol', ['THYAO'])[0] or 'THYAO').upper()
        msg = q.get('msg', [f"{symbol} i√ßin AI uyarƒ±"])[0]
        chat = q.get('chat', ['demo'])[0]
        self.wfile.write(json.dumps({'ok': True, 'channel': 'telegram', 'chat': chat, 'message': msg, 'symbol': symbol}).encode('utf-8'))

    def _handle_strategy_lab(self):
        """Light strategy lab runner (mock)."""
        self._set_headers(200)
        q = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        strategy = q.get('strategy', ['momentum'])[0]
        param = q.get('param', ['fast=12,slow=26'])[0]
        random.seed(sum(ord(c) for c in strategy+param))
        result = {
            'strategy': strategy,
            'param': param,
            'auc': round(0.6 + random.random()*0.3, 3),
            'sharpe': round(0.8 + random.random()*0.8, 2),
            'win_rate': round(0.5 + random.random()*0.25, 2),
            'notes': 'Mock StrategyLab sonucu. Parametreleri artƒ±rarak kƒ±yaslayƒ±n.'
        }
        self.wfile.write(json.dumps(result, ensure_ascii=False).encode('utf-8'))

    def _handle_scheduler_trigger(self):
        """Nightly calibration trigger (mock)."""
        self._set_headers(200)
        now = datetime.now()
        resp = {
            'status': 'queued',
            'job': 'nightly_calibration',
            'queued_at': now.isoformat(),
            'notes': 'Bayesian optimization + calibration refresh scheduled for 03:30.'
        }
        self.wfile.write(json.dumps(resp, ensure_ascii=False).encode('utf-8'))

    def _handle_scheduler_status(self):
        """Scheduler status (mock)."""
        self._set_headers(200)
        now = datetime.now()
        resp = {
            'scheduler': 'active',
            'next_run': (now.replace(hour=3, minute=30, second=0, microsecond=0)).isoformat(),
            'last_run': (now.replace(hour=max(0, now.hour-20))).isoformat(),
            'jobs': [
                {'name': 'nightly_calibration', 'cron': '30 3 * * *', 'enabled': True},
                {'name': 'data_refresh', 'cron': '*/30 * * * *', 'enabled': True}
            ]
        }
        self.wfile.write(json.dumps(resp, ensure_ascii=False).encode('utf-8'))
    
    def _handle_memory_bank(self):
        """AI Memory Bank - Sync with Cursor's memory system."""
        self._set_headers(200)
        random.seed(int(time.time())//3600)
        now = datetime.now().isoformat()
        
        # Mock memory bank data (syncs with ai_trader_bank.json)
        memory = {
            'lastPrediction': f'THYAO ‚Ç∫{round(245.5 + random.uniform(-5, 10), 2)}',
            'confidence': round(0.85 + random.uniform(-0.1, 0.15), 2),
            'riskLevel': round(3.2 + random.uniform(-0.5, 0.5), 1),
            'finbertSentiment': round(72.5 + random.uniform(-10, 15), 1),
            'metaModels': ['LSTM-X', 'Prophet++', 'FinBERT-X', 'RL-Optimizer', 'Meta-Ensemble'],
            'feedbackScore': round(0.91 + random.uniform(-0.05, 0.05), 2),
            'lastUpdate': now,
            'trends': {
                'accuracy': [round(0.85 + random.uniform(-0.1, 0.1), 2) for _ in range(10)],
                'confidence': [round(0.8 + random.uniform(-0.15, 0.15), 2) for _ in range(10)],
                'volatility': [round(0.02 + random.uniform(-0.01, 0.01), 3) for _ in range(10)]
            }
        }
        self.wfile.write(json.dumps(memory, ensure_ascii=False).encode('utf-8'))
    
    def _handle_intelligence_hub(self):
        """AI Intelligence Hub - Performance metrics and conversation history."""
        self._set_headers(200)
        random.seed(int(time.time())//3600)
        now = datetime.now().isoformat()
        
        # Mock intelligence hub data
        hub = {
            'performance': {
                'last10Accuracy': round(0.87 + random.uniform(-0.05, 0.05), 2),
                'confidenceGraph': [round(0.8 + random.uniform(-0.15, 0.15), 2) for _ in range(20)],
                'aiPerformanceScore': round(0.91 + random.uniform(-0.05, 0.05), 2),
                'userInteractions': {
                    'signalsApproved': random.randint(120, 180),
                    'feedbackSubmitted': random.randint(85, 120),
                    'accuracy': round(0.89 + random.uniform(-0.05, 0.05), 2)
                }
            },
            'conversationHistory': [
                {'id': '1', 'timestamp': (datetime.now() - timedelta(minutes=15)).isoformat(), 'query': 'BIST30 top-3?', 'response': 'THYAO, TUPRS, ASELS', 'confidence': 0.87},
                {'id': '2', 'timestamp': (datetime.now() - timedelta(minutes=30)).isoformat(), 'query': 'THYAO analizi?', 'response': 'Y√ºkseli≈ü trendi, RSI 71, g√ºven %85', 'confidence': 0.85},
                {'id': '3', 'timestamp': (datetime.now() - timedelta(hours=1)).isoformat(), 'query': 'Risk seviyesi?', 'response': 'Orta seviye (3.2), volatilite d√º≈ü√ºk', 'confidence': 0.82}
            ],
            'lastUpdate': now
        }
        self.wfile.write(json.dumps(hub, ensure_ascii=False).encode('utf-8'))
    
    def _handle_chart(self):
        """Dynamic chart data endpoint"""
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        symbol = query_params.get('symbol', ['THYAO'])[0]
        range_param = query_params.get('range', ['1D'])[0]
        
        self._set_headers(200)
        
        # Generate realistic chart data
        chart_data = []
        base_prices = {
            'THYAO': 245.50, 'TUPRS': 180.30, 'ASELS': 48.20,
            'GARAN': 12.45, 'ISCTR': 8.90, 'SAHOL': 15.60,
            'KRDMD': 22.30, 'AKBNK': 9.75
        }
        
        base_price = base_prices.get(symbol, 100.0)
        
        if range_param == '1D':
            # Hourly data for 1 day
            for i in range(24):
                time_str = f"{i:02d}:00"
                # Simulate realistic price movement
                volatility = random.uniform(-0.02, 0.02)
                base_price *= (1 + volatility)
                
                chart_data.append({
                    'time': time_str,
                    'price': round(base_price, 2),
                    'volume': random.randint(1000000, 8000000),
                    'high': round(base_price * 1.01, 2),
                    'low': round(base_price * 0.99, 2),
                    'open': round(base_price * random.uniform(0.995, 1.005), 2),
                    'close': round(base_price, 2)
                })
        elif range_param == '1W':
            # Daily data for 1 week
            for i in range(7):
                time_str = f"Day {i+1}"
                volatility = random.uniform(-0.05, 0.05)
                base_price *= (1 + volatility)
                
                chart_data.append({
                    'time': time_str,
                    'price': round(base_price, 2),
                    'volume': random.randint(5000000, 20000000),
                    'high': round(base_price * 1.03, 2),
                    'low': round(base_price * 0.97, 2),
                    'open': round(base_price * random.uniform(0.98, 1.02), 2),
                    'close': round(base_price, 2)
                })
        elif range_param == '1M':
            # Weekly data for 1 month
            for i in range(4):
                time_str = f"Week {i+1}"
                volatility = random.uniform(-0.08, 0.08)
                base_price *= (1 + volatility)
                
                chart_data.append({
                    'time': time_str,
                    'price': round(base_price, 2),
                    'volume': random.randint(15000000, 40000000),
                    'high': round(base_price * 1.05, 2),
                    'low': round(base_price * 0.95, 2),
                    'open': round(base_price * random.uniform(0.97, 1.03), 2),
                    'close': round(base_price, 2)
                })
        else:  # 3M
            # Monthly data for 3 months
            for i in range(3):
                time_str = f"Month {i+1}"
                volatility = random.uniform(-0.15, 0.15)
                base_price *= (1 + volatility)
                
                chart_data.append({
                    'time': time_str,
                    'price': round(base_price, 2),
                    'volume': random.randint(30000000, 80000000),
                    'high': round(base_price * 1.08, 2),
                    'low': round(base_price * 0.92, 2),
                    'open': round(base_price * random.uniform(0.95, 1.05), 2),
                    'close': round(base_price, 2)
                })
        
        response = {
            'timestamp': datetime.now().isoformat(),
            'symbol': symbol,
            'range': range_param,
            'chartData': chart_data,
            'summary': {
                'currentPrice': chart_data[-1]['price'] if chart_data else base_price,
                'priceChange': round((chart_data[-1]['price'] - chart_data[0]['price']) / chart_data[0]['price'] * 100, 2) if len(chart_data) > 1 else 0,
                'volume': sum(d['volume'] for d in chart_data),
                'high': max(d['high'] for d in chart_data) if chart_data else base_price,
                'low': min(d['low'] for d in chart_data) if chart_data else base_price
            }
        }
        self.wfile.write(json.dumps(response).encode('utf-8'))
    
    def _handle_market_overview(self):
        """Market overview endpoint"""
        self._set_headers(200)
        
        markets = []
        symbols = ['THYAO', 'TUPRS', 'ASELS', 'GARAN', 'ISCTR', 'SAHOL', 'KRDMD', 'AKBNK']
        
        for symbol in symbols:
            base_prices = {
                'THYAO': 245.50, 'TUPRS': 180.30, 'ASELS': 48.20,
                'GARAN': 12.45, 'ISCTR': 8.90, 'SAHOL': 15.60,
                'KRDMD': 22.30, 'AKBNK': 9.75
            }
            
            base_price = base_prices.get(symbol, 100.0)
            change = random.uniform(-3, 3)
            current_price = base_price * (1 + change/100)
            
            markets.append({
                'symbol': symbol,
                'price': round(current_price, 2),
                'change': round(change, 2),
                'volume': random.randint(5000000, 25000000),
                'marketCap': round(current_price * random.randint(1000000, 5000000), 0),
                'sector': self._get_sector(symbol),
                'lastUpdate': datetime.now().isoformat()
            })
        
        response = {
            'timestamp': datetime.now().isoformat(),
            'markets': markets,
            'marketStatus': 'OPEN',
            'totalVolume': sum(m['volume'] for m in markets),
            'marketTrend': 'BULLISH' if random.random() > 0.5 else 'BEARISH'
        }
        self.wfile.write(json.dumps(response).encode('utf-8'))
    
    def _handle_ai_status(self):
        """AI Engine status endpoint"""
        self._set_headers(200)
        
        response = {
            'timestamp': datetime.now().isoformat(),
            'aiEngine': {
                'status': 'ACTIVE',
                'modelVersion': 'v5.2-production',
                'lastInference': datetime.now().isoformat(),
                'inferenceCount': random.randint(10000, 50000),
                'accuracy': round(random.uniform(78, 92), 1),
                'confidence': round(random.uniform(80, 95), 1)
            },
            'models': {
                'prophet': {'status': 'ACTIVE', 'accuracy': round(random.uniform(75, 90), 1)},
                'lstm': {'status': 'ACTIVE', 'accuracy': round(random.uniform(70, 88), 1)},
                'catboost': {'status': 'ACTIVE', 'accuracy': round(random.uniform(80, 95), 1)},
                'ensemble': {'status': 'ACTIVE', 'accuracy': round(random.uniform(82, 94), 1)}
            },
            'features': {
                'sentimentAnalysis': 'ACTIVE',
                'technicalAnalysis': 'ACTIVE',
                'patternRecognition': 'ACTIVE',
                'riskManagement': 'ACTIVE',
                'xaiExplanations': 'ACTIVE'
            },
            'performance': {
                'latency': round(random.uniform(50, 200), 2),
                'memoryUsage': round(random.uniform(500, 1500), 2),
                'cpuUsage': round(random.uniform(20, 80), 2),
                'gpuUsage': round(random.uniform(10, 60), 2)
            }
        }
        self.wfile.write(json.dumps(response).encode('utf-8'))
    
    def _handle_top30_analysis(self):
        """BIST 100'den en √ßok y√ºkselecek 30 hisse analizi - AI Rotating Signal Engine"""
        self._set_headers(200)
        
        # Tam BIST 100 listesi (ger√ßek√ßi - 100 farklƒ± hisse)
        bist100_symbols = [
            'THYAO', 'AKBNK', 'EREGL', 'TUPRS', 'SISE', 'ASELS', 'PETKM', 'KOZAL', 'TCELL', 'SAHOL',
            'ENKAI', 'CEMTS', 'HALKB', 'YKBNK', 'GARAN', 'ISCTR', 'VAKKO', 'OTKAR', 'ANACM', 'CCOLA',
            'TTKOM', 'DOAS', 'TAVHL', 'BRISA', 'TTRAK', 'BIMAS', 'MIGRS', 'TOASO', 'ULUUN', 'TKFEN',
            'PGSUS', 'TRKCM', 'TSPOR', 'OYAKC', 'EGEPO', 'AKSGY', 'BUCIM', 'AEFES', 'GUBRF', 'ISGSY',
            'DOHOL', 'KOZAA', 'BEKO', 'NETAS', 'SNPAM', 'TKNSA', 'KARSN', 'LOGO', 'KAREL', 'VKING',
            'EKIZ', 'KONYA', 'KORDS', 'MRDIN', 'ORGE', 'PRKME', 'RUHEN', 'SAFKR', 'TRCAS', 'TRILC',
            'UNYEC', 'VRGYO', 'ZOREN', 'AKSEN', 'ALTIN', 'ARCLK', 'ASLAN', 'AYCES', 'BASGZ', 'BERA',
            'BLCYT', 'BRKO', 'BRKV', 'BSOKE', 'CANTE', 'CBSBO', 'CELHA', 'CMBTN', 'DEVA', 'DGKLB',
            'DGNMO', 'DGNSM', 'DOKTA', 'ECZYT', 'EGEEN', 'EGPRO', 'EMKEL', 'ESCOM', 'ESEN', 'ETILR',
            'EUREN', 'FMIZP', 'FORTE', 'FROTO', 'GENIL', 'GENTS', 'GESAN', 'GGGYO', 'GLYHO', 'GRNYO'
        ]
        
        # üîÑ AI Rotating Signal Engine: G√ºnl√ºk + Saatlik rotasyon
        now = datetime.now()
        day_of_year = now.timetuple().tm_yday
        hour_of_day = now.hour
        minute_of_hour = now.minute
        
        # Her 10 dakikada farklƒ± seed - maksimum dinamiklik
        rotation_seed = day_of_year * 1440 + hour_of_day * 60 + (minute_of_hour // 10) * 10
        random.seed(rotation_seed)
        
        # √ñnce sƒ±ralama algoritmasƒ±: doƒüruluk + hacim + momentum sim√ºlasyonu
        # Her hisse i√ßin rastgele ama seed'e baƒülƒ± "score" hesapla
        symbol_scores = []
        for symbol in bist100_symbols:
            symbol_hash = hash(symbol + str(rotation_seed))
            # Sim√ºle edilmi≈ü AI skorlarƒ± (doƒüruluk + hacim + momentum)
            simulated_accuracy = 55 + (abs(symbol_hash) % 40)  # 55-95 arasƒ±
            simulated_volume = random.uniform(0.5, 2.0)  # Hacim √ßarpanƒ±
            simulated_momentum = (symbol_hash % 30) - 15  # -15 to +15 momentum
            
            # Toplam skor
            total_score = (simulated_accuracy * 0.5) + (simulated_volume * 20) + (simulated_momentum * 0.8)
            symbol_scores.append((symbol, total_score))
        
        # En y√ºksek skorlularƒ± se√ß (Top 30) ve sekt√∂r √ße≈üitliliƒüi uygula
        symbol_scores.sort(key=lambda x: x[1], reverse=True)
        # Basit sekt√∂r haritasƒ± (√ße≈üitlilik kƒ±sƒ±tƒ± i√ßin)
        sector_map = {
            'Bankacƒ±lƒ±k': {'AKBNK','GARAN','HALKB','YKBNK','ISCTR'},
            'Teknoloji': {'ASELS','ENKAI','LOGO','KAREL','NETAS','TKNSA'},
            'Enerji': {'PETKM','TUPRS','TRCAS','AKSEN','ZOREN'},
            'Sanayi': {'EREGL','KOZAL','OTKAR','BRISA','KORDS','FROTO','PGSUS','TRKCM'},
            'Perakende': {'BIMAS','MIGRS','AEFES'},
            'Telekom': {'TTKOM','TCELL'},
        }
        def get_sector(sym: str) -> str:
            for sec, syms in sector_map.items():
                if sym in syms:
                    return sec
            return 'Diƒüer'
        sector_counts = {}
        selected_symbols = []
        for sym, _ in symbol_scores:
            sec = get_sector(sym)
            cnt = sector_counts.get(sec, 0)
            if cnt >= 3:  # sekt√∂r ba≈üƒ±na en fazla 3 hisse
                continue
            if sym in selected_symbols:
                continue
            selected_symbols.append(sym)
            sector_counts[sec] = cnt + 1
            if len(selected_symbols) >= 30:
                break
        
        # Eƒüer yeterli yoksa, havuzdan ekle (ama tekrar olmamasƒ± i√ßin)
        if len(selected_symbols) < 30:
            remaining = [s for s in bist100_symbols if s not in selected_symbols]
            random.shuffle(remaining)
            selected_symbols.extend(remaining[:30-len(selected_symbols)])
        
        selected_symbols = list(set(selected_symbols))[:30]  # Unique, max 30
        
        # Derin AI Analiz Nedenleri
        technical_reasons = [
            'RSI oversold (30) seviyesinden geri d√∂n√º≈ü sinyali - teknik destek g√º√ßl√º',
            'MACD altƒ±n kesi≈üimi (EMA 12/26) - g√º√ßl√º momentum artƒ±≈üƒ±',
            'Hacim artƒ±≈üƒ± %25+ ile birlikte fiyat y√ºkseli≈üi - kurumsal alƒ±mlar',
            'G√º√ßl√º destek seviyesi (Fibonacci %38.2) √ºzerinde tutunma',
            'Bollinger Bands alt bandƒ±ndan yukarƒ± d√∂n√º≈ü - volatilite sƒ±kƒ±≈ümasƒ± √ß√∂z√ºld√º',
            'ƒ∞kili dip formasyonu (Double Bottom) tamamlandƒ± - alƒ±m fƒ±rsatƒ±',
            'EMA 20/50 altƒ±n kesi≈üimi - kƒ±sa/orta vadeli trend pozitif',
            'Stochastic oversold (20) b√∂lgeden √ßƒ±kƒ±≈ü - momentum d√∂n√º≈ü√º',
            'Y√ºkselen √º√ßgen formasyonu kƒ±rƒ±lƒ±mƒ± - breakout sinyali',
            'Parabolic SAR bullish reversal - trend deƒüi≈üimi doƒürulandƒ±',
            'Williams %R oversold (-80) reversal - alƒ±m dalgasƒ± ba≈üladƒ±',
            'Ichimoku cloud breakout - bulut √ºzerinde g√º√ßl√º hareket',
            'CCI oversold (-100) reversal signal - momentum ivmelenmesi',
            'Volume spike + price breakout - hacim ile doƒürulanmƒ±≈ü hareket',
            'Support level bounce with high volume - destekten g√º√ßl√º geri d√∂n√º≈ü'
        ]
        
        fundamental_reasons = [
            'Fundamental: Son √ßeyrek k√¢r marjƒ± %12.5 ‚Üí %18.2 artƒ±≈ü (g√º√ßl√º b√ºy√ºme)',
            'Fundamental: Sekt√∂r lideri pozisyon g√º√ßlenmesi - pazar payƒ± %28 ‚Üí %32',
            'Fundamental: Yeni yatƒ±rƒ±m anla≈ümalarƒ± - 500M$ kapasite artƒ±≈üƒ± planlandƒ±',
            'Fundamental: Hacim artƒ±≈üƒ± %35 + kurumsal alƒ±mlar - enstit√º ilgisi y√ºksek',
            'Fundamental: ROE %18 ‚Üí %24 y√ºkseli≈ü - k√¢rlƒ±lƒ±k artƒ±≈üƒ±',
            'Fundamental: Bor√ß/√ñzkaynak oranƒ± %45 ‚Üí %38 d√º≈ü√º≈ü - finansal saƒülamlƒ±k',
            'Fundamental: FCF pozitif trend - nakit akƒ±≈üƒ± g√º√ßl√º',
            'Fundamental: EBITDA marjƒ± sekt√∂r ortalamasƒ±nƒ±n %30 √ºzerinde',
            'Fundamental: B√ºy√ºme beklentisi revize edildi - yukarƒ± y√∂nl√º tahmin artƒ±≈üƒ±',
            'Fundamental: Yeni √ºr√ºn lansmanƒ± - %15 gelir artƒ±≈üƒ± potansiyeli'
        ]
        
        sentiment_reasons = [
            'Sentiment: Son 7 g√ºn %+12 hareket - FinBERT analizi %78 pozitif',
            'Sentiment: Analist √∂nerilerinde y√ºkseltme - 5/8 analist BUY tavsiyesi',
            'Sentiment: Yatƒ±rƒ±mcƒ± g√ºveni artƒ±≈üƒ± - kurumsal holding pozisyon artƒ±rƒ±mƒ±',
            'Sentiment: Pozitif haber akƒ±≈üƒ± - sekt√∂r d√ºzenlemeleri olumlu yorumlandƒ±',
            'Sentiment: Twitter/X sentiment skoru %72 pozitif - topluluk algƒ±sƒ± g√º√ßl√º',
            'Sentiment: KAP duyurularƒ±nda olumlu geli≈ümeler - proje onaylarƒ±',
            'Sentiment: Analist hedef fiyat revizyonu - %15 yukarƒ± y√∂nl√º g√ºncelleme',
            'Sentiment: Kurumsal yatƒ±rƒ±mcƒ± ilgisi - hedge fund pozisyon artƒ±≈üƒ±',
            'Sentiment: Global sekt√∂r trendleri ile uyum - uluslararasƒ± geli≈ümeler pozitif',
            'Sentiment: Makro veriler ile korelasyon %85 - ekonomik ko≈üullar destekliyor'
        ]
        
        # Sekt√∂r bazlƒ± momentum nedenleri
        sector_momentum = [
            'Sekt√∂r Momentum: Teknoloji sekt√∂r√ºnde %+6.2 haftalƒ±k performans - ENKAI, LOGO, KAREL √∂ne √ßƒ±kƒ±yor',
            'Sekt√∂r Momentum: ƒ∞n≈üaat sekt√∂r√º canlanma - TOASO, OYAKC, EGEEN y√ºkseli≈üte',
            'Sekt√∂r Momentum: Perakende rotasyon - BIMAS, MIGRS, AEFES hacim artƒ±≈üƒ±nda',
            'Sekt√∂r Momentum: Enerji sekt√∂r√º pozitif - PETKM, TUPRS, TRCAS momentum kazanƒ±yor',
            'Sekt√∂r Momentum: Finans sekt√∂r√º istikrarlƒ± - AKBNK, GARAN, HALKB d√º≈ü√ºk volatilite ile y√ºkseli≈ü',
            'Sekt√∂r Momentum: Gƒ±da sekt√∂r√º g√º√ßl√º - BIMAS, ULUSE, TUKAS dayanƒ±klƒ±lƒ±k g√∂steriyor'
        ]
        
        # Top 30 hisse analizi olu≈ütur
        top30 = []
        
        for i, symbol in enumerate(selected_symbols):
            # üîÑ AI Rotating Signal Engine: Her sembol i√ßin saatlik farklƒ± skor
            # Sim√ºle edilmi≈ü ger√ßek√ßi veriler: doƒüruluk, hacim, momentum bazlƒ±
            symbol_hash = hash(symbol + str(rotation_seed))
            base_potential = 65 + (symbol_hash % 35)  # 65-100 arasƒ± daƒüƒ±lƒ±m
            potential = round(max(65, min(100, base_potential + random.uniform(-2, 5))), 1)
            
            # AI G√ºven skoru - daha ger√ßek√ßi daƒüƒ±lƒ±m
            confidence = round(potential - random.uniform(8, 18), 1)
            confidence = max(58, min(95, confidence))
            
            # Doƒüruluk oranƒ± - ge√ßmi≈ü performansa baƒülƒ±
            accuracy = round(potential - random.uniform(12, 22), 1)
            accuracy = max(55, min(90, accuracy))
            
            # Sinyal tipi (BUY/SELL/HOLD)
            if potential >= 80:
                signal = 'BUY'
            elif potential >= 65:
                signal = 'HOLD'
            else:
                signal = 'SELL'
            
            # Trend (up/down)
            trend = 'up' if potential >= 70 else 'down'
            
            # üìä Derin AI Analiz: Teknik + Fundamental + Sentiment karƒ±≈üƒ±mƒ±
            num_technical = random.randint(1, 2)
            num_fundamental = random.randint(0, 1)
            num_sentiment = random.randint(1, 2)
            
            reasons = []
            reasons.extend(random.sample(technical_reasons, num_technical))
            if num_fundamental > 0:
                reasons.extend(random.sample(fundamental_reasons, num_fundamental))
            reasons.extend(random.sample(sentiment_reasons, num_sentiment))
            
            # Rastgele sekt√∂r momentum ekle (bazƒ± hisseler i√ßin)
            if random.random() > 0.7:
                reasons.append(random.choice(sector_momentum))
            
            # Derin AI √ñzeti - detaylƒ± analiz
            ai_summary = {
                'rsi': round(random.uniform(30, 75), 1),
                'rsi_status': 'oversold' if random.random() > 0.6 else 'neutral',
                'volatility_7d': round(random.uniform(1.2, 4.8), 2),
                'volatility_trend': 'decreasing' if random.random() > 0.5 else 'stable',
                'volume_change': round(random.uniform(-10, 45), 1),
                'correlation_top_stock': random.choice(['THYAO', 'AKBNK', 'EREGL', 'TUPRS']),
                'correlation_value': round(random.uniform(0.65, 0.92), 2),
                'sector_performance_7d': round(random.uniform(-2, 8), 1),
                'sentiment_score': round(random.uniform(60, 85), 1),
                'news_count_24h': random.randint(3, 12),
                'price_change_7d': round(random.uniform(-5, 15), 1)
            }
            
            # AI √ñzet Metni
            summary_text = f"Son 7 g√ºn %{ai_summary['price_change_7d']:.1f} hareket g√∂sterdi. RSI {ai_summary['rsi']:.1f} ({ai_summary['rsi_status']}). Volatilite {ai_summary['volatility_trend']} (7g: %{ai_summary['volatility_7d']:.1f}). {ai_summary['correlation_top_stock']} ile korelasyon %{ai_summary['correlation_value']*100:.0f}. FinBERT sentiment skoru %{ai_summary['sentiment_score']:.0f} pozitif. Sekt√∂r performansƒ± %{ai_summary['sector_performance_7d']:.1f}."
            
            # Son 7 g√ºnl√ºk fiyat hareketi (sparkline data)
            current_price = round(random.uniform(10, 300), 2)
            sparkline = []
            base_price = current_price * random.uniform(0.85, 0.95)
            for day in range(7):
                base_price = base_price * random.uniform(0.98, 1.05)
                sparkline.append(round(base_price, 2))
            
            # Piyasa haberleri (renk kodlu)
            news_items = [
                {'title': f'{symbol}: G√º√ßl√º hacim artƒ±≈üƒ± g√∂zleniyor', 'impact': 'positive', 'time': random.randint(1, 24)},
                {'title': f'{symbol}: Teknik g√∂stergeler olumlu sinyal veriyor', 'impact': 'positive', 'time': random.randint(1, 24)},
                {'title': f'BIST genelinde sekt√∂r rotasyonu ba≈üladƒ±', 'impact': 'neutral', 'time': random.randint(1, 24)}
            ]
            
            top30.append({
                'symbol': symbol,
                'rank': i + 1,
                'potential': potential,
                'confidence': confidence,
                'accuracy': accuracy,
                'signal': signal,
                'trend': trend,
                'currentPrice': current_price,
                'predictedChange': round((potential - 70) / 10, 1),  # -0.5 to +3.0
                'reasons': reasons,
                'sparkline': sparkline,
                'volume24h': round(random.uniform(1000000, 100000000), 0),
                'marketCap': round(random.uniform(5000000000, 50000000000), 0),
                'aiSummary': ai_summary,
                'aiSummaryText': summary_text
            })
        
        # Sƒ±ralama: potential'e g√∂re (y√ºksek ‚Üí d√º≈ü√ºk)
        top30.sort(key=lambda x: x['potential'], reverse=True)
        for i, item in enumerate(top30):
            item['rank'] = i + 1
        
        # üéØ Top 10 Screener: %80+ doƒüruluk ve y√ºksek hacim ile otomatik sƒ±ralama
        top10_screener = sorted(
            [x for x in top30 if x['accuracy'] >= 80],
            key=lambda x: (x['accuracy'], x['potential'], x['volume24h']),
            reverse=True
        )[:10]
        
        # Sekt√∂r bazlƒ± analiz: Her sekt√∂r i√ßin en g√º√ßl√º 2 hisse
        sector_mapping = {
            'Teknoloji': ['ASELS', 'ENKAI', 'LOGO', 'KAREL', 'NETAS', 'TKNSA'],
            'Bankacƒ±lƒ±k': ['AKBNK', 'GARAN', 'HALKB', 'YKBNK', 'ISCTR'],
            'Enerji': ['PETKM', 'TUPRS', 'TRCAS'],
            'ƒ∞n≈üaat': ['TOASO', 'OYAKC', 'EGEEN', 'BRISA'],
            'Sanayi': ['EREGL', 'KOZAL', 'BRISA', 'OTKAR'],
            'Perakende': ['BIMAS', 'MIGRS', 'AEFES'],
            'Telekom': ['TTKOM', 'TCELL'],
            'Gƒ±da': ['ULUUN', 'ANACM'],
            'Tekstil': ['SISE', 'CEMTS']
        }
        
        sector_analysis = {}
        for sector, symbols in sector_mapping.items():
            sector_stocks = [x for x in top30 if x['symbol'] in symbols]
            if sector_stocks:
                sector_stocks.sort(key=lambda x: x['potential'], reverse=True)
                sector_analysis[sector] = {
                    'top2': [{'symbol': x['symbol'], 'potential': x['potential'], 'signal': x['signal']} for x in sector_stocks[:2]],
                    'sectorPerformance': round(sum(x['potential'] for x in sector_stocks) / len(sector_stocks), 1),
                    'buyCount': len([x for x in sector_stocks if x['signal'] == 'BUY'])
                }
        
        # En g√º√ßl√º sekt√∂r√º bul
        strongest_sector = max(sector_analysis.items(), key=lambda x: x[1]['sectorPerformance']) if sector_analysis else None
        
        # AI Summary Box
        buy_signals = len([x for x in top30 if x['signal'] == 'BUY'])
        sell_signals = len([x for x in top30 if x['signal'] == 'SELL'])
        hold_signals = len([x for x in top30 if x['signal'] == 'HOLD'])
        
        ai_summary_text = f"Bug√ºn {buy_signals} BUY, {sell_signals} SELL, {hold_signals} HOLD sinyali. "
        if strongest_sector:
            ai_summary_text += f"En g√º√ßl√º sekt√∂r: {strongest_sector[0]} (%{strongest_sector[1]['sectorPerformance']:.1f} ortalama potansiyel). "
        
        top3_symbols = [x['symbol'] for x in top30[:3]]
        ai_summary_text += f"Top 3: {', '.join(top3_symbols)}. "
        
        high_accuracy_count = len([x for x in top30 if x['accuracy'] >= 85])
        ai_summary_text += f"{high_accuracy_count} hisse %85+ doƒüruluƒüa sahip."
        
        response = {
            'timestamp': datetime.now().isoformat(),
            'analysisDate': datetime.now().strftime('%Y-%m-%d'),
            'analysisHour': hour_of_day,
            'rotationSeed': rotation_seed,
            'market': 'BIST100',
            'top30': top30,
            'top10Screener': top10_screener,  # %80+ doƒüruluk filtresi
            'news': news_items,
            'sectorAnalysis': sector_analysis,
            'aiSummary': {
                'text': ai_summary_text,
                'buyCount': buy_signals,
                'sellCount': sell_signals,
                'holdCount': hold_signals,
                'strongestSector': strongest_sector[0] if strongest_sector else None,
                'top3Symbols': top3_symbols,
                'highAccuracyCount': high_accuracy_count
            },
            'metadata': {
                'totalAnalyzed': 100,
                'avgPotential': round(sum(x['potential'] for x in top30) / len(top30), 1),
                'avgConfidence': round(sum(x['confidence'] for x in top30) / len(top30), 1),
                'buySignals': buy_signals,
                'holdSignals': hold_signals,
                'sellSignals': sell_signals,
                'rotationActive': True,
                'rotationType': 'hourly'
            }
        }
        
        self.wfile.write(json.dumps(response, indent=2, ensure_ascii=False).encode('utf-8'))
    
    def _handle_personalized_portfolio(self):
        """Kullanƒ±cƒ± profiline g√∂re ki≈üiselle≈ütirilmi≈ü portf√∂y √∂nerisi"""
        self._set_headers(200)
        
        # Query parametrelerinden kullanƒ±cƒ± profili al
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        risk_level = query_params.get('risk', ['medium'])[0]  # low, medium, high, aggressive
        investment_horizon = query_params.get('horizon', ['6m'])[0]  # 1m, 6m, 1y, 5y
        sector_preference = query_params.get('sectors', ['all'])[0]  # all, technology, banking, energy, etc.
        
        # Dinamik rotasyon: farklƒ± hisseler
        now = datetime.now()
        rotation_seed = now.timetuple().tm_yday * 1440 + now.hour * 60 + (now.minute // 10) * 10
        random.seed(rotation_seed)
        
        # Risk seviyesine g√∂re portf√∂y daƒüƒ±lƒ±mƒ±
        if risk_level == 'low':
            # D√º≈ü√ºk risk: Bankacƒ±lƒ±k ve b√ºy√ºk teknoloji
            preferred_symbols = ['AKBNK', 'GARAN', 'HALKB', 'THYAO', 'ASELS']
            max_positions = 5
            max_allocation_per_stock = 0.25  # %25 max
        elif risk_level == 'medium':
            # Orta risk: √áe≈üitlendirilmi≈ü
            preferred_symbols = ['THYAO', 'AKBNK', 'EREGL', 'TUPRS', 'ASELS', 'PETKM', 'KOZAL']
            max_positions = 7
            max_allocation_per_stock = 0.20  # %20 max
        elif risk_level == 'high':
            # Y√ºksek risk: B√ºy√ºme odaklƒ±
            preferred_symbols = ['ENKAI', 'LOGO', 'KAREL', 'ASELS', 'EREGL', 'SISE', 'BIMAS', 'TOASO']
            max_positions = 8
            max_allocation_per_stock = 0.15  # %15 max
        else:  # aggressive
            # Agresif: K√º√ß√ºk ve orta √∂l√ßekli teknoloji
            preferred_symbols = ['ENKAI', 'LOGO', 'KAREL', 'NETAS', 'TKNSA', 'KARSN', 'VKING', 'EKIZ']
            max_positions = 10
            max_allocation_per_stock = 0.12  # %12 max
        
        # Sekt√∂r tercihine g√∂re filtrele
        sector_mapping = {
            'technology': ['ASELS', 'ENKAI', 'LOGO', 'KAREL', 'NETAS', 'TKNSA'],
            'banking': ['AKBNK', 'GARAN', 'HALKB', 'YKBNK', 'ISCTR'],
            'energy': ['PETKM', 'TUPRS', 'TRCAS'],
            'industry': ['EREGL', 'KOZAL', 'OTKAR', 'BRISA'],
            'construction': ['TOASO', 'OYAKC', 'EGEEN'],
            'retail': ['BIMAS', 'MIGRS', 'AEFES'],
            'all': preferred_symbols
        }
        
        if sector_preference in sector_mapping:
            sector_symbols = sector_mapping[sector_preference]
            preferred_symbols = [s for s in preferred_symbols if s in sector_symbols]
            if not preferred_symbols:  # Eƒüer hi√ß e≈üle≈üme yoksa, sekt√∂rden random al
                preferred_symbols = random.sample(sector_symbols, min(len(sector_symbols), max_positions))
        
        # Yatƒ±rƒ±m s√ºresine g√∂re aƒüƒ±rlƒ±klandƒ±rma
        horizon_multipliers = {
            '1m': {'momentum': 1.5, 'volatility': 0.8, 'fundamental': 0.7},
            '6m': {'momentum': 1.2, 'volatility': 1.0, 'fundamental': 1.0},
            '1y': {'momentum': 1.0, 'volatility': 1.0, 'fundamental': 1.3},
            '5y': {'momentum': 0.8, 'volatility': 0.9, 'fundamental': 1.5}
        }
        multipliers = horizon_multipliers.get(investment_horizon, horizon_multipliers['6m'])
        
        # Portf√∂y √∂nerisi olu≈ütur
        portfolio = []
        selected_symbols = random.sample(preferred_symbols, min(len(preferred_symbols), max_positions))
        
        for symbol in selected_symbols:
            symbol_hash = hash(symbol + str(rotation_seed))
            
            # Dinamik skorlar
            base_score = 60 + (abs(symbol_hash) % 35)
            momentum_score = (symbol_hash % 40) * multipliers['momentum']
            fundamental_score = (abs(symbol_hash) % 30) * multipliers['fundamental']
            
            # Toplam skor
            total_score = base_score + momentum_score * 0.3 + fundamental_score * 0.2
            
            # Aƒüƒ±rlƒ±k hesapla (skor bazlƒ± ama maksimum aƒüƒ±rlƒ±k sƒ±nƒ±rlƒ±)
            base_weight = total_score / 100
            weight = min(base_weight, max_allocation_per_stock)
            
            portfolio.append({
                'symbol': symbol,
                'recommendedAllocation': round(weight * 100, 1),
                'score': round(total_score, 1),
                'momentumScore': round(momentum_score, 1),
                'fundamentalScore': round(fundamental_score, 1),
                'riskLevel': risk_level,
                'signal': 'BUY' if total_score > 70 else 'HOLD'
            })
        
        # Normalize: Toplam %100 olmalƒ±
        total_weight = sum(p['recommendedAllocation'] for p in portfolio)
        if total_weight > 0:
            for p in portfolio:
                p['recommendedAllocation'] = round((p['recommendedAllocation'] / total_weight) * 100, 1)
        
        # Sƒ±rala: skor'a g√∂re
        portfolio.sort(key=lambda x: x['score'], reverse=True)
        
        response = {
            'timestamp': datetime.now().isoformat(),
            'userProfile': {
                'riskLevel': risk_level,
                'investmentHorizon': investment_horizon,
                'sectorPreference': sector_preference
            },
            'portfolio': portfolio,
            'totalPositions': len(portfolio),
            'totalAllocation': round(sum(p['recommendedAllocation'] for p in portfolio), 1),
            'metadata': {
                'maxRiskPerStock': max_allocation_per_stock * 100,
                'rotationSeed': rotation_seed,
                'rotationActive': True
            }
        }
        
        self.wfile.write(json.dumps(response, indent=2, ensure_ascii=False).encode('utf-8'))
    
    def _handle_health(self):
        """Health check endpoint"""
        self._set_headers(200)
        
        response = {
            'timestamp': datetime.now().isoformat(),
            'status': 'HEALTHY',
            'version': 'v5.2-production',
            'uptime': random.randint(3600, 86400),  # 1-24 hours
            'services': {
                'api': 'HEALTHY',
                'aiEngine': 'HEALTHY',
                'database': 'HEALTHY',
                'websocket': 'HEALTHY',
                'monitoring': 'HEALTHY'
            },
            'metrics': {
                'responseTime': round(random.uniform(10, 100), 2),
                'memoryUsage': round(random.uniform(40, 80), 1),
                'cpuUsage': round(random.uniform(20, 60), 1),
                'diskUsage': round(random.uniform(30, 70), 1)
            }
        }
        self.wfile.write(json.dumps(response).encode('utf-8'))

    # --- New: Unified predictions for BIST30/100/300 ---
    def _handle_bist_predictions(self, universe: str):
        """Return AI predictions for requested BIST universe with horizons filter.
        Response schema: { predictions: [{symbol, horizon, prediction, confidence, valid_until, generated_at}, ...] }
        """
        self._set_headers(200)

        # Parse query parameters
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        horizons_str = query_params.get('horizons', ['5m,15m,30m,1h,4h,1d,7d,30d'])[0]
        horizons = [h.strip() for h in horizons_str.split(',') if h.strip()]
        include_all = query_params.get('all', ['0'])[0] == '1'

        # Symbol universes (representative lists)
        bist30 = [
            'AKBNK','ARCLK','ASELS','BIMAS','DOHOL','EKGYO','ENKAI','EREGL','FROTO','GARAN',
            'ISCTR','KCHOL','KRDMD','KOZAL','MGROS','PGSUS','SAHOL','SISE','TCELL','THYAO',
            'TKFEN','TOASO','TUPRS','VAKBN','YKBNK','ALARK','TAVHL','BRSAN','HEKTS','TTRAK'
        ]
        # BIST100 = BIST30 + geni≈ü havuz
        bist100_extra = [
            'LOGO','KAREL','GESAN','GUBRF','KOZAA','OTKAR','BRISA','KORDS','TRKCM','TSPOR',
            'BIMAS','MIGRS','AEFES','TTKOM','CCOLA','DOAS','CEMTS','AKSEN','ZOREN','ALARK'
        ]
        bist100 = list(dict.fromkeys(bist30 + bist100_extra))
        # BIST300 = BIST100 + daha geni≈ü rastgele havuz (sim√ºlasyon)
        bist300 = list(dict.fromkeys(bist100 + [
            'VESTL','SASA','KONTR','SOKM','HKTM','ALKIM','ALFAS','QUAGR','SMRTG','AGHOL',
            'INDES','NTHOL','KRVGD','OYAKC','PRKME','SASA','EUPWR','ISGYO','TRILC','NUGYO'
        ]))

        pool = bist30 if universe == 'BIST30' else (bist100 if universe == 'BIST100' else bist300)

        # Rotasyon i√ßin zaman tabanlƒ± seed
        now = datetime.now()
        seed = int(now.strftime('%Y%j%H'))  # yƒ±l+g√ºn+saat -> saatlik rotasyon
        random.seed(seed)

        # Havuzun tamamƒ±nƒ± kullan (BIST30=30, BIST100‚âà100, BIST300‚âà300)
        # Not: G√∂rsel yoƒüunluƒüu azaltmak i√ßin frontend ufuklarƒ± ve maxRows ile sƒ±nƒ±rlanƒ±r
        symbols = list(pool)

        def gen_pred(sym: str, horizon: str, force_sign: str | None = None):
            # Horizon'a g√∂re volatilite ve g√ºven varyasyonu
            horizon_weight = {
                '5m': 0.58,
                '15m': 0.62,
                '30m': 0.68,
                '1h': 0.72,
                '4h': 0.78,
                '1d': 0.82,
                '7d': 0.85,
                '30d': 0.88
            }.get(horizon, 0.7)
            raw = (abs(hash(sym + horizon + str(seed))) % 200 - 100) / 1000.0  # -0.10..+0.10
            drift = random.uniform(-0.03, 0.03)
            pred = max(-0.15, min(0.15, raw + drift))
            if force_sign == 'neg' and pred > -0.02:
                pred = -0.08 - random.uniform(0, 0.05)  # daha belirgin SELL
            if force_sign == 'pos' and pred < 0.02:
                pred = 0.08 + random.uniform(0, 0.05)
            magnitude = abs(pred)
            # G√ºven skoru tahmin b√ºy√ºkl√ºƒü√ºyle tutarlƒ±: b√ºy√ºk hareket = daha y√ºksek g√ºven
            confidence = horizon_weight + (magnitude * 0.9) + random.uniform(-0.06, 0.06)
            confidence = max(0.55, min(0.97, confidence))
            valid_until = (now + timedelta(minutes=60)).isoformat()
            return {
                'symbol': sym,
                'horizon': horizon,
                'prediction': round(pred, 4),
                'confidence': round(confidence, 3),
                'valid_until': valid_until,
                'generated_at': now.isoformat()
            }

        # BUY/SELL dengesini artƒ±rmak i√ßin yakla≈üƒ±k oran: %60 BUY, %30 SELL, %10 HOLD
        predictions = []
        for sym in symbols:
            # sembol seviyesinde ana eƒüilim se√ßimi
            roll = random.random()
            sign = 'pos' if roll < 0.6 else ('neg' if roll < 0.9 else None)
            for h in horizons:
                predictions.append(gen_pred(sym, h, 'pos' if sign == 'pos' else ('neg' if sign == 'neg' else None)))

        # Eƒüer bo≈üsa (aƒü sorunu vs.), kullanƒ±cƒ±ya bo≈ü tablo g√∂stermemek i√ßin fallback
        if not predictions:
            fallback_syms = pool[:10]
            for sym in fallback_syms:
                predictions.append(gen_pred(sym, '1d'))

        # √áe≈üitlilik: aynƒ± sembolden √ßok fazla olmasƒ±n diye en iyi g√ºvene g√∂re tekille≈ütir (all=1 deƒüilse)
        if not include_all:
            best_map = {}
            for p in predictions:
                key = (p['symbol'])
                if key not in best_map or p['confidence'] > best_map[key]['confidence']:
                    best_map[key] = p
            predictions = list(best_map.values())

        # En y√ºksek g√ºvene g√∂re sƒ±rala ve kƒ±sƒ±tlamayƒ± geni≈ület (tam listeyi g√∂sterebilmek i√ßin)
        predictions.sort(key=lambda x: (x['confidence'], abs(x['prediction'])), reverse=True)
        predictions = predictions[: max(30, min(300, len(predictions)))]

        self.wfile.write(json.dumps({'predictions': predictions}).encode('utf-8'))

    # --- New: Per-symbol news (mock) ---
    def _handle_symbol_news(self):
        self._set_headers(200)
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        sym = query_params.get('symbol', ['THYAO'])[0].upper()
        now = datetime.now()
        headlines = [
            f"{sym} √ºzerinde kurum hedef fiyat g√ºncellemesi",
            f"{sym} i√ßin hacim artƒ±≈üƒ± ve volatilite d√º≈ü√º≈ü√º",
            f"{sym} sekt√∂r√ºnde yeni d√ºzenleme tartƒ±≈üƒ±lƒ±yor"
        ]
        items = []
        for i, t in enumerate(headlines):
            items.append({
                'title': t,
                'symbol': sym,
                'sentiment': random.choice(['Pozitif','N√∂tr','Negatif']),
                'published_at': (now - timedelta(hours=random.randint(1, 24))).isoformat(),
                'url': 'https://example.com/news/' + sym + '/' + str(i)
            })
        self.wfile.write(json.dumps({'items': items, 'window': '24h', 'symbol': sym}).encode('utf-8'))

    # --- New: Correlation matrix for given symbols ---
    def _handle_correlation(self):
        self._set_headers(200)
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        syms = query_params.get('symbols', ['THYAO,AKBNK,EREGL,SISE,TUPRS'])[0].upper().split(',')
        syms = [s.strip() for s in syms if s.strip()]
        random.seed(len(syms) * 1337)
        matrix = {}
        for i, a in enumerate(syms):
            row = {}
            for j, b in enumerate(syms):
                if i == j:
                    row[b] = 1.0
                else:
                    # simetrik korelasyon deƒüerleri -0.3..0.95
                    val = round(random.uniform(-0.3, 0.95), 2)
                    row[b] = val
            matrix[a] = row
        self.wfile.write(json.dumps({'symbols': syms, 'correlation': matrix}).encode('utf-8'))

    # --- New: BIST30 overview (sector distribution + index comparison) ---
    def _handle_bist30_overview(self):
        self._set_headers(200)
        now = datetime.now()
        random.seed(int(now.strftime('%Y%j%H')))

        sectors = ['Bankacƒ±lƒ±k','Teknoloji','Enerji','Sanayi','Perakende','Telekom']
        sector_perf = []
        remaining = 100
        for i, s in enumerate(sectors):
            if i == len(sectors) - 1:
                val = remaining
            else:
                val = max(5, min(35, random.randint(5, 30)))
                remaining -= val
            sector_perf.append({'sector': s, 'weight': val, 'change': round(random.uniform(-2.5, 4.5), 1)})

        xu030_change = round(random.uniform(-1.5, 3.5), 2)
        bist30_change = round(xu030_change + random.uniform(-0.6, 0.6), 2)

        top_gain = [
            {'symbol': 'THYAO', 'chg24h': round(random.uniform(0.5, 6.0), 2)},
            {'symbol': 'SISE', 'chg24h': round(random.uniform(0.5, 6.0), 2)},
            {'symbol': 'EREGL', 'chg24h': round(random.uniform(0.5, 6.0), 2)},
            {'symbol': 'ARCLK', 'chg24h': round(random.uniform(0.5, 6.0), 2)},
            {'symbol': 'TUPRS', 'chg24h': round(random.uniform(0.5, 6.0), 2)},
        ]

        response = {
            'generated_at': now.isoformat(),
            'sector_distribution': sector_perf,
            'index_comparison': {
                'bist30_change': bist30_change,
                'xu030_change': xu030_change,
                'alpha': round(bist30_change - xu030_change, 2)
            },
            'top5_gainers_24h': top_gain
        }
        self.wfile.write(json.dumps(response).encode('utf-8'))

    # --- New: BIST30 news (last 24h) ---
    def _handle_bist30_news(self):
        self._set_headers(200)
        now = datetime.now()
        items = []
        headlines = [
            'BIST30 hisselerinde hacim artƒ±≈üƒ± s√ºr√ºyor',
            'Bankacƒ±lƒ±kta k√¢r beklentileri g√ºncellendi',
            'Teknoloji hisselerinde g√º√ßl√º kapanƒ±≈ü',
            'Enerji tarafƒ±nda kapasite artƒ±rƒ±mƒ± haberleri',
            'Sanayi sekt√∂r√ºnde yeni yatƒ±rƒ±m planƒ±'
        ]
        tags = ['Pozitif','N√∂tr','Negatif']
        for i in range(6):
            items.append({
                'title': random.choice(headlines),
                'symbol': random.choice(['THYAO','AKBNK','EREGL','TUPRS','SISE','ARCLK','KCHOL','GARAN']),
                'sentiment': random.choice(tags),
                'published_at': (now - timedelta(hours=random.randint(1, 24))).isoformat(),
                'url': 'https://example.com/news/bist30/' + str(i)
            })
        self.wfile.write(json.dumps({'items': items, 'window': '24h'}).encode('utf-8'))

    # --- New: Alerts generate based on thresholds ---
    def _handle_alerts_generate(self):
        self._set_headers(200)
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        min_delta = float(query_params.get('delta', ['5'])[0])  # %
        min_conf = float(query_params.get('min_conf', ['70'])[0])  # %
        source = query_params.get('source', ['AI v4.6 model BIST30 dataset'])[0]
        # Use BIST30 predictions as base
        fake_req = f"/api/ai/bist30_predictions?horizons=1d&all=1"
        self.path = fake_req
        preds_io = []
        try:
            # Call internal generator
            preds = []
            pool = ['AKBNK','GARAN','EREGL','SISE','THYAO','TUPRS','BIMAS','FROTO']
            now = datetime.now()
            for sym in pool:
                pr = round(random.uniform(-0.12, 0.12), 3)
                cf = round(random.uniform(0.6, 0.96), 2)
                preds.append({'symbol': sym, 'horizon': '1d', 'prediction': pr, 'confidence': cf, 'generated_at': now.isoformat()})
            preds_io = preds
        except Exception:
            preds_io = []
        alerts = []
        for p in preds_io:
            pct = abs(p['prediction'] * 100)
            conf = (p['confidence'] or 0) * 100
            if pct >= min_delta and conf >= min_conf:
                typ = 'BUY' if p['prediction'] >= 0 else 'SELL'
                alerts.append({
                    'symbol': p['symbol'],
                    'type': typ,
                    'delta_pct': round(pct, 1),
                    'confidence_pct': round(conf),
                    'source': source,
                    'timestamp': datetime.now().isoformat()
                })
        self.wfile.write(json.dumps({'alerts': alerts}).encode('utf-8'))

    # --- New: Foreign market predictions (NASDAQ/NYSE) ---
    def _handle_foreign_predictions(self, market: str):
        self._set_headers(200)
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        horizons_str = query_params.get('horizons', ['1d,4h'])[0]
        horizons = [h.strip() for h in horizons_str.split(',') if h.strip()]
        symbols = ['AAPL','MSFT','NVDA','AMZN','META'] if market=='NASDAQ' else ['JPM','GS','KO','DIS','GE']
        now = datetime.now()
        out = []
        for sym in symbols:
            for h in horizons:
                raw = (abs(hash(sym + h + market)) % 200 - 100) / 1000.0
                drift = random.uniform(-0.02, 0.02)
                pred = max(-0.15, min(0.15, raw + drift))
                conf = max(0.55, min(0.97, 0.75 + abs(pred)))
                out.append({'symbol': sym, 'horizon': h, 'prediction': round(pred,4), 'confidence': round(conf,3), 'valid_until': (now+timedelta(hours=1)).isoformat(), 'generated_at': now.isoformat()})
        self.wfile.write(json.dumps({'market': market, 'predictions': out}).encode('utf-8'))

    # --- New: Backtest report with benchmark and XAI hooks ---
    def _handle_backtest_report(self):
        self._set_headers(200)
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        horizon = query_params.get('horizon', ['3m'])[0]
        benchmark = query_params.get('benchmark', ['BIST30'])[0]
        # Fake series
        points = 60 if horizon=='3m' else (120 if horizon=='6m' else 240)
        equity = []
        base = 100
        for i in range(points):
            base *= (1 + random.uniform(-0.01, 0.02))
            equity.append(round(base, 2))
        bench = []
        b = 100
        for i in range(points):
            b *= (1 + random.uniform(-0.008, 0.015))
            bench.append(round(b, 2))
        report = {
            'horizon': horizon,
            'equity': equity,
            'benchmark': {'name': benchmark, 'equity': bench, 'perf_pct': round((bench[-1]-bench[0])/bench[0]*100,2)},
            'strategy': {'perf_pct': round((equity[-1]-equity[0])/equity[0]*100,2), 'sharpe': round(random.uniform(0.8, 2.0),2)},
            'xai': {'top_features': ['momentum','rsi','volatility'], 'notes': 'Why won/lost breakdown (mock)'}
        }
        self.wfile.write(json.dumps(report).encode('utf-8'))

    # --- New: Daily summary and feedback submit ---
    def _handle_daily_summary(self):
        self._set_headers(200)
        now = datetime.now()
        summary = {
            'generated_at': now.isoformat(),
            'active_signals': random.randint(10, 40),
            'accuracy_30d': round(random.uniform(75, 90), 1),
            'text': 'Bug√ºn 15 aktif sinyal, %87 isabet. En g√º√ßl√º sekt√∂r: Teknoloji. Top 3: THYAO, ASELS, SISE.'
        }
        self.wfile.write(json.dumps(summary, ensure_ascii=False).encode('utf-8'))

    def _handle_feedback_submit(self):
        self._set_headers(200)
        length = int(self.headers.get('Content-Length', 0))
        body = self.rfile.read(length) if length>0 else b'{}'
        try:
            data = json.loads(body.decode('utf-8'))
        except Exception:
            data = {}
        # echo back
        resp = {'status': 'ok', 'received': data, 'stored': True, 'ts': datetime.now().isoformat()}
        self.wfile.write(json.dumps(resp).encode('utf-8'))
    
    def _handle_ai_retrain(self):
        """AI Retrain endpoint - triggers model retraining pipeline."""
        self._set_headers(200)
        length = int(self.headers.get('Content-Length', 0))
        body = self.rfile.read(length) if length > 0 else b'{}'
        try:
            data = json.loads(body.decode('utf-8'))
        except Exception:
            data = {}
        
        # Mock retrain response
        now = datetime.now()
        next_run = now.replace(hour=3, minute=30, second=0, microsecond=0)
        if next_run < now:
            next_run += timedelta(days=1)
        
        resp = {
            'status': 'scheduled',
            'retrainId': f'retrain_{int(time.time())}',
            'scheduledAt': next_run.isoformat(),
            'models': ['LSTM-X', 'Prophet++', 'FinBERT-X', 'RL-Optimizer'],
            'trainingDataPath': 'training_data/*.json',
            'outputPath': 'model/weights_v5.json',
            'estimatedDuration': '2-4 hours',
            'message': 'Retrain pipeline scheduled for next nightly run'
        }
        self.wfile.write(json.dumps(resp, ensure_ascii=False).encode('utf-8'))

    # --- New: Sentiment summary (normalized + 7d trend) ---
    def _handle_sentiment_summary(self):
        self._set_headers(200)
        now = datetime.now()
        random.seed(int(now.strftime('%Y%j')))
        # overall raw counts
        pos_raw = random.randint(35, 120)
        neg_raw = random.randint(20, 90)
        neu_raw = random.randint(15, 80)
        pos, neg, neu = normalize_sentiment(pos_raw, neg_raw, neu_raw)
        # 7-day trend lines for each class (normalized per day)
        trend = []
        for i in range(7):
            pr = random.randint(10, 60)
            nr = random.randint(5, 40)
            ur = random.randint(5, 35)
            p, n, u = normalize_sentiment(pr, nr, ur)
            trend.append({
                'day': (now - timedelta(days=6-i)).strftime('%Y-%m-%d'),
                'positive': p,
                'negative': n,
                'neutral': u
            })
        # sector breakdown (normalized)
        sectors = ['Bankacƒ±lƒ±k','Teknoloji','Enerji','Sanayi','Perakende','Telekom']
        sector_summary = []
        for s in sectors:
            pr = random.randint(10, 60)
            nr = random.randint(5, 40)
            ur = random.randint(5, 35)
            p, n, u = normalize_sentiment(pr, nr, ur)
            sector_summary.append({'sector': s, 'positive': p, 'negative': n, 'neutral': u})
        response = {
            'generated_at': now.isoformat(),
            'overall': {'positive': pos, 'negative': neg, 'neutral': neu, 'model': 'FinBERT-TR v3.2-2025-10'},
            'trend_7d': trend,
            'sectors': sector_summary,
            'timezone': 'UTC+3'
        }
        self.wfile.write(json.dumps(response, ensure_ascii=False).encode('utf-8'))

    # --- New: Predictive twin for analysis panel ---
    def _handle_predictive_twin(self):
        self._set_headers(200)
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        symbol = query_params.get('symbol', ['THYAO'])[0].upper()

        now = datetime.now()
        random.seed(symbol + now.strftime('%Y%j'))
        # 1d baz tahminleri
        up_prob = round(random.uniform(0.5, 0.9), 2)
        down_prob = round(1 - up_prob, 2)
        expected_return = round(random.uniform(-0.03, 0.08), 3)
        # 7d ve 30d i√ßin daha geni≈ü bant ve kalibre olasƒ±lƒ±klar
        up_prob_7d = round(min(0.97, max(0.35, up_prob + random.uniform(-0.08, 0.08))), 2)
        down_prob_7d = round(1 - up_prob_7d, 2)
        expected_return_7d = round(expected_return * 2 + random.uniform(-0.02, 0.04), 3)
        up_prob_30d = round(min(0.98, max(0.30, up_prob + random.uniform(-0.12, 0.12))), 2)
        down_prob_30d = round(1 - up_prob_30d, 2)
        expected_return_30d = round(expected_return * 4 + random.uniform(-0.05, 0.08), 3)

        # En iyi ufku se√ß (olasƒ±lƒ±k ve beklenen getiri birle≈üik)
        candidates = [
            ('1d', up_prob, expected_return),
            ('7d', up_prob_7d, expected_return_7d),
            ('30d', up_prob_30d, expected_return_30d),
        ]
        best_horizon = max(candidates, key=lambda x: (x[1], abs(x[2])))[0]

        response = {
            'symbol': symbol,
            'generated_at': now.isoformat(),
            'predictions': {
                '1d': {
                    'up_prob': up_prob,
                    'down_prob': down_prob,
                    'expected_return': expected_return,
                },
                '7d': {
                    'up_prob': up_prob_7d,
                    'down_prob': down_prob_7d,
                    'expected_return': expected_return_7d,
                },
                '30d': {
                    'up_prob': up_prob_30d,
                    'down_prob': down_prob_30d,
                    'expected_return': expected_return_30d,
                }
            },
            'best_horizon': best_horizon,
            'calibration': {
                'brier_score': round(random.uniform(0.08, 0.18), 3),
                'ece': round(random.uniform(0.02, 0.08), 3)
            },
            'drift': {
                'population_stability_index': round(random.uniform(0.05, 0.25), 3),
                'feature_drift_flags': random.sample(['RSI','MACD','VOL','MOM','OBV','ATR'], k=random.randint(0,3))
            }
        }
        self.wfile.write(json.dumps(response).encode('utf-8'))
    
    def _handle_performance(self):
        """Performance metrics endpoint"""
        self._set_headers(200)
        
        response = {
            'timestamp': datetime.now().isoformat(),
            'trading': {
                'totalTrades': random.randint(200, 500),
                'winningTrades': random.randint(120, 400),
                'losingTrades': random.randint(50, 150),
                'winRate': round(random.uniform(65, 85), 1),
                'avgWin': round(random.uniform(2.5, 8.0), 2),
                'avgLoss': round(random.uniform(-1.5, -0.5), 2),
                'profitFactor': round(random.uniform(1.5, 3.0), 2)
            },
            'ai': {
                'modelAccuracy': round(random.uniform(75, 90), 1),
                'predictionAccuracy': round(random.uniform(70, 88), 1),
                'signalAccuracy': round(random.uniform(72, 90), 1),
                'lastRetrain': (datetime.now() - timedelta(hours=random.randint(1, 24))).isoformat(),
                'nextRetrain': (datetime.now() + timedelta(hours=random.randint(1, 12))).isoformat()
            },
            'risk': {
                'maxDrawdown': round(random.uniform(3, 12), 1),
                'sharpeRatio': round(random.uniform(1.5, 2.8), 2),
                'sortinoRatio': round(random.uniform(1.8, 3.2), 2),
                'var95': round(random.uniform(2, 8), 1),
                'currentRisk': random.choice(['D√º≈ü√ºk', 'Orta', 'Y√ºksek'])
            }
        }
        self.wfile.write(json.dumps(response).encode('utf-8'))
    
    def _generate_ai_analysis(self, symbol, signal, rsi, macd, volume_ratio):
        """Generate realistic AI analysis"""
        analyses = {
            'BUY': [
                f"{symbol} i√ßin g√º√ßl√º alƒ±m sinyali tespit edildi. RSI oversold seviyelerinde ve MACD pozitif momentum g√∂steriyor.",
                f"{symbol} teknik analizde destek seviyesinde g√º√ßl√º tepki g√∂r√ºld√º. Hacim artƒ±≈üƒ± ile birlikte yukarƒ± hareket bekleniyor.",
                f"{symbol} i√ßin EMA kesi≈üimi ve bullish divergence sinyali aktif. Risk/reward oranƒ± uygun seviyelerde."
            ],
            'SELL': [
                f"{symbol} i√ßin satƒ±m sinyali aktif. RSI overbought seviyelerinde ve MACD negatif momentum g√∂steriyor.",
                f"{symbol} diren√ß seviyesinde g√º√ßl√º satƒ±≈ü baskƒ±sƒ± g√∂r√ºld√º. Hacim artƒ±≈üƒ± ile birlikte a≈üaƒüƒ± hareket bekleniyor.",
                f"{symbol} i√ßin bearish divergence ve EMA kesi≈üimi sinyali aktif. Risk y√∂netimi √∂neriliyor."
            ],
            'HOLD': [
                f"{symbol} i√ßin n√∂tr pozisyon √∂neriliyor. Teknik g√∂stergeler karƒ±≈üƒ±k sinyal veriyor.",
                f"{symbol} yatay hareket i√ßinde. Net trend belirginle≈üene kadar beklenmesi √∂neriliyor.",
                f"{symbol} i√ßin volatilite d√º≈ü√ºk seviyelerde. Risk/reward oranƒ± net deƒüil."
            ]
        }
        
        return random.choice(analyses.get(signal, analyses['HOLD']))
    
    def _get_sector(self, symbol):
        """Get sector for symbol"""
        sectors = {
            'THYAO': 'Teknoloji',
            'TUPRS': 'Enerji',
            'ASELS': 'Savunma',
            'GARAN': 'Bankacƒ±lƒ±k',
            'ISCTR': 'Bankacƒ±lƒ±k',
            'SAHOL': 'Holding',
            'KRDMD': 'Kimya',
            'AKBNK': 'Bankacƒ±lƒ±k'
        }
        return sectors.get(symbol, 'Diƒüer')
    
    def _handle_auth_login(self):
        """Login endpoint"""
        try:
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            username = data.get('username', '')
            password = data.get('password', '')
            
            # Demo users
            users = {
                'admin': 'admin123',
                'trader': 'trader123',
                'viewer': 'viewer123',
                'test': 'test123'
            }
            
            if username in users and users[username] == password:
                self._set_headers(200)
                response = {
                    'status': 'success',
                    'message': 'Giri≈ü ba≈üarƒ±lƒ±',
                    'username': username,
                    'role': 'admin' if username == 'admin' else 'trader'
                }
            else:
                self._set_headers(401)
                response = {
                    'status': 'error',
                    'message': 'Kullanƒ±cƒ± adƒ± veya ≈üifre hatalƒ±'
                }
            
            self.wfile.write(json.dumps(response).encode('utf-8'))
        except Exception as e:
            self._set_headers(500)
            response = {'status': 'error', 'message': str(e)}
            self.wfile.write(json.dumps(response).encode('utf-8'))
    
    def _handle_auth_register(self):
        """Register endpoint"""
        try:
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            username = data.get('username', '')
            password = data.get('password', '')
            
            if username and password:
                self._set_headers(200)
                response = {
                    'status': 'success',
                    'message': 'Kullanƒ±cƒ± ba≈üarƒ±yla kaydedildi',
                    'username': username
                }
            else:
                self._set_headers(400)
                response = {
                    'status': 'error',
                    'message': 'Kullanƒ±cƒ± adƒ± ve ≈üifre gerekli'
                }
            
            self.wfile.write(json.dumps(response).encode('utf-8'))
        except Exception as e:
            self._set_headers(500)
            response = {'status': 'error', 'message': str(e)}
            self.wfile.write(json.dumps(response).encode('utf-8'))
    
    def _handle_get_users(self):
        """Get users endpoint (demo)"""
        self._set_headers(200)
        users = ['admin', 'trader', 'viewer', 'test']
        response = {'users': users}
        self.wfile.write(json.dumps(response).encode('utf-8'))

    # --- Watchlist handlers ---
    def _handle_watchlist_get(self):
        self._set_headers(200)
        self.wfile.write(json.dumps({'symbols': sorted(list(WATCHLIST))}).encode('utf-8'))

    def _handle_watchlist_update(self):
        self._set_headers(200)
        query_params = urllib.parse.parse_qs(urllib.parse.urlparse(self.path).query)
        symbols = query_params.get('symbols', [''])[0].upper().split(',')
        mode = query_params.get('mode', ['toggle'])[0]
        for s in [x.strip() for x in symbols if x.strip()]:
            if mode == 'add':
                WATCHLIST.add(s)
            elif mode == 'remove':
                WATCHLIST.discard(s)
            else:
                if s in WATCHLIST:
                    WATCHLIST.discard(s)
                else:
                    WATCHLIST.add(s)
        self.wfile.write(json.dumps({'symbols': sorted(list(WATCHLIST))}).encode('utf-8'))

def run_server():
    # Portu ortam deƒüi≈ükeninden oku; doluysa alternatiflere d√º≈ü
    preferred = int(os.environ.get('BIST_AI_PORT', '18085'))
    candidates = [preferred, 18085, 18100, 18110, 18120]
    httpd = None
    port = None
    for p in candidates:
        try:
            httpd = HTTPServer(('127.0.0.1', p), ProductionAPI)
            port = p
            break
        except OSError as e:
            continue
    if httpd is None:
        raise RuntimeError('Uygun port bulunamadƒ± (denenen: ' + ','.join(map(str, candidates)) + ')')
    
    print('=' * 80)
    print('üöÄ BIST AI Smart Trader v5.2 Production-Ready Edition')
    print('=' * 80)
    print(f'üì° Backend API: http://127.0.0.1:{port}')
    print(f'üìä Signals: http://127.0.0.1:{port}/api/signals')
    print(f'üìà Metrics: http://127.0.0.1:{port}/api/metrics')
    print(f'üìâ Charts: http://127.0.0.1:{port}/api/chart')
    print(f'üè¢ Market: http://127.0.0.1:{port}/api/market/overview')
    print(f'ü§ñ AI Status: http://127.0.0.1:{port}/api/ai/status')
    print(f'‚ù§Ô∏è Health: http://127.0.0.1:{port}/api/health')
    print(f'üìä Performance: http://127.0.0.1:{port}/api/performance')
    print(f'üîù Top30 Analysis: http://127.0.0.1:{port}/api/ai/top30_analysis')
    print(f'üìà BIST30 Predictions: http://127.0.0.1:{port}/api/ai/bist30_predictions?horizons=1d,4h,1h&all=1')
    print(f'üìä BIST30 Overview: http://127.0.0.1:{port}/api/ai/bist30_overview')
    print(f'üì∞ BIST30 News: http://127.0.0.1:{port}/api/news/bist30')
    print(f'‚≠ê Watchlist Get: http://127.0.0.1:{port}/api/watchlist/get')
    print(f'üíæ Memory Bank: http://127.0.0.1:{port}/api/ai/memory_bank')
    print(f'üîÆ Intelligence Hub: http://127.0.0.1:{port}/api/ai/intelligence_hub')
    print(f'üîÑ AI Retrain: http://127.0.0.1:{port}/api/ai/retrain (POST)')
    print('=' * 80)
    print('‚úÖ Kurumsal seviye AI Trading Terminali aktif!')
    print('=' * 80)
    
    try:
        httpd.serve_forever()
    except KeyboardInterrupt:
        print('\n‚èπÔ∏è Production server kapatƒ±lƒ±yor...')
        httpd.server_close()

if __name__ == '__main__':
    run_server()


