#!/usr/bin/env python3
"""
ðŸ¤– RL Portfolio Agent
PRD v2.0 - FinRL based portfolio optimization
"""

import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import yfinance as yf

logger = logging.getLogger(__name__)

@dataclass
class PortfolioAction:
    """Portfolio aksiyonu"""
    symbol: str
    action: str  # 'BUY', 'SELL', 'HOLD'
    allocation: float  # 0-1 arasÄ±
    confidence: float
    reason: str
    expected_return: float
    risk_score: float

class RLPortfolioAgent:
    """RL Portfolio AjanÄ±"""
    
    def __init__(self, initial_balance: float = 100000.0):
        self.initial_balance = initial_balance
        self.current_balance = initial_balance
        self.portfolio = {}
        self.action_history = []
        
    def optimize_portfolio(self, symbols: List[str], signals: Dict) -> List[PortfolioAction]:
        """Portfolio optimizasyonu"""
        logger.info(f"ðŸŽ¯ {len(symbols)} hisse iÃ§in portfolio optimizasyonu...")
        
        actions = []
        
        for symbol in symbols:
            if symbol in signals:
                signal_data = signals[symbol]
                
                # Basit RL mantÄ±ÄŸÄ±
                action = self._determine_action(symbol, signal_data)
                actions.append(action)
        
        logger.info(f"âœ… Portfolio optimizasyonu tamamlandÄ±: {len(actions)} aksiyon")
        return actions
    
    def _determine_action(self, symbol: str, signal_data: Dict) -> PortfolioAction:
        """Aksiyon belirle"""
        confidence = signal_data.get('confidence', 0.5)
        
        if confidence > 0.8:
            action_type = 'BUY'
            allocation = 0.3
        elif confidence < 0.3:
            action_type = 'SELL'
            allocation = 0.0
        else:
            action_type = 'HOLD'
            allocation = 0.1
        
        return PortfolioAction(
            symbol=symbol,
            action=action_type,
            allocation=allocation,
            confidence=confidence,
            reason=f"Signal confidence: {confidence:.2f}",
            expected_return=signal_data.get('upside_pct', 0.0),
            risk_score=1.0 - confidence
        )

def test_rl_agent():
    """RL Agent test"""
    logger.info("ðŸ§ª RL Portfolio Agent test...")
    
    agent = RLPortfolioAgent()
    test_symbols = ["GARAN.IS", "AKBNK.IS"]
    test_signals = {
        "GARAN.IS": {"confidence": 0.85, "upside_pct": 5.0},
        "AKBNK.IS": {"confidence": 0.75, "upside_pct": 3.0}
    }
    
    actions = agent.optimize_portfolio(test_symbols, test_signals)
    
    for action in actions:
        logger.info(f"ðŸ“ˆ {action.symbol}: {action.action} - {action.allocation:.1%}")
    
    return actions

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    test_rl_agent()
