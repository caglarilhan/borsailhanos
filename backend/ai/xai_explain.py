"""
ğŸš€ BIST AI Smart Trader - XAI Explainability Engine
==================================================

SHAP & LIME ile model kararlarÄ±nÄ± aÃ§Ä±klayan sistem.
Hisse bazÄ±nda "Neden bu sinyal?" aÃ§Ä±klamasÄ± verir.

Ã–zellikler:
- SHAP (SHapley Additive exPlanations)
- LIME (Local Interpretable Model-agnostic Explanations)
- Feature importance analysis
- Model decision explanations
- Interactive explanations
"""

import asyncio
import json
import logging
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import pickle

# XAI Libraries
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False
    print("âš ï¸ SHAP not available - install with: pip install shap")

try:
    import lime
    import lime.tabular
    LIME_AVAILABLE = True
except ImportError:
    LIME_AVAILABLE = False
    print("âš ï¸ LIME not available - install with: pip install lime")

# ML Libraries
try:
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import train_test_split
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("âš ï¸ Scikit-learn not available")

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ExplanationResult:
    """AÃ§Ä±klama sonucu"""
    symbol: str
    prediction: str
    confidence: float
    shap_values: Dict[str, float]
    lime_explanation: Dict[str, Any]
    feature_importance: Dict[str, float]
    decision_factors: List[str]
    timestamp: datetime
    
    def to_dict(self):
        data = asdict(self)
        data['timestamp'] = self.timestamp.isoformat()
        return data

@dataclass
class FeatureExplanation:
    """Feature aÃ§Ä±klamasÄ±"""
    feature_name: str
    feature_value: float
    importance_score: float
    contribution: float
    explanation: str
    
    def to_dict(self):
        return asdict(self)

class XAIExplainEngine:
    """XAI aÃ§Ä±klama motoru"""
    
    def __init__(self, models_dir: str = "backend/ai/models"):
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        # Model cache
        self.loaded_models: Dict[str, Any] = {}
        self.scalers: Dict[str, StandardScaler] = {}
        
        # Explanation cache
        self.explanation_cache: Dict[str, ExplanationResult] = {}
        
        # Feature names (teknik indikatÃ¶rler)
        self.feature_names = [
            'close_price', 'sma_20', 'sma_50', 'ema_12', 'ema_26',
            'macd', 'macd_signal', 'rsi', 'bb_upper', 'bb_middle', 'bb_lower',
            'volume_ratio', 'price_change', 'volume_change', 'volatility'
        ]
        
        # Feature aÃ§Ä±klamalarÄ±
        self.feature_descriptions = {
            'close_price': 'GÃ¼ncel fiyat',
            'sma_20': '20 gÃ¼nlÃ¼k basit hareketli ortalama',
            'sma_50': '50 gÃ¼nlÃ¼k basit hareketli ortalama',
            'ema_12': '12 gÃ¼nlÃ¼k Ã¼stel hareketli ortalama',
            'ema_26': '26 gÃ¼nlÃ¼k Ã¼stel hareketli ortalama',
            'macd': 'MACD deÄŸeri',
            'macd_signal': 'MACD sinyal Ã§izgisi',
            'rsi': 'RSI (Relative Strength Index)',
            'bb_upper': 'Bollinger BantlarÄ± Ã¼st Ã§izgisi',
            'bb_middle': 'Bollinger BantlarÄ± orta Ã§izgisi',
            'bb_lower': 'Bollinger BantlarÄ± alt Ã§izgisi',
            'volume_ratio': 'Hacim oranÄ±',
            'price_change': 'Fiyat deÄŸiÅŸimi',
            'volume_change': 'Hacim deÄŸiÅŸimi',
            'volatility': 'Volatilite'
        }
    
    def load_model(self, model_type: str, model_path: str) -> bool:
        """Modeli yÃ¼kle"""
        try:
            if model_path in self.loaded_models:
                return True
            
            if model_path.endswith('.pkl'):
                with open(model_path, 'rb') as f:
                    model = pickle.load(f)
            elif model_path.endswith('.h5'):
                # TensorFlow model
                from tensorflow.keras.models import load_model
                model = load_model(model_path)
            else:
                logger.error(f"âŒ Unsupported model format: {model_path}")
                return False
            
            self.loaded_models[model_path] = model
            logger.info(f"âœ… Model loaded: {model_type} from {model_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Load model error: {e}")
            return False
    
    def prepare_features(self, data: Dict[str, float]) -> np.ndarray:
        """Feature'larÄ± hazÄ±rla"""
        try:
            features = []
            
            for feature_name in self.feature_names:
                value = data.get(feature_name, 0.0)
                features.append(value)
            
            return np.array(features).reshape(1, -1)
            
        except Exception as e:
            logger.error(f"âŒ Prepare features error: {e}")
            return np.zeros((1, len(self.feature_names)))
    
    def explain_with_shap(self, model, features: np.ndarray, model_type: str) -> Dict[str, float]:
        """SHAP ile aÃ§Ä±klama"""
        try:
            if not SHAP_AVAILABLE:
                logger.warning("âš ï¸ SHAP not available")
                return {}
            
            # SHAP explainer oluÅŸtur
            if model_type == 'tree':
                explainer = shap.TreeExplainer(model)
            elif model_type == 'neural':
                explainer = shap.DeepExplainer(model, features)
            else:
                explainer = shap.Explainer(model)
            
            # SHAP deÄŸerlerini hesapla
            shap_values = explainer.shap_values(features)
            
            # Feature importance hesapla
            if isinstance(shap_values, list):
                shap_values = shap_values[0]  # Ä°lk sÄ±nÄ±f iÃ§in
            
            feature_importance = {}
            for i, feature_name in enumerate(self.feature_names):
                feature_importance[feature_name] = float(abs(shap_values[0][i]))
            
            logger.info(f"âœ… SHAP explanation completed")
            return feature_importance
            
        except Exception as e:
            logger.error(f"âŒ SHAP explanation error: {e}")
            return {}
    
    def explain_with_lime(self, model, features: np.ndarray, model_type: str) -> Dict[str, Any]:
        """LIME ile aÃ§Ä±klama"""
        try:
            if not LIME_AVAILABLE:
                logger.warning("âš ï¸ LIME not available")
                return {}
            
            # LIME explainer oluÅŸtur
            explainer = lime.tabular.LimeTabularExplainer(
                features,
                feature_names=self.feature_names,
                class_names=['SELL', 'HOLD', 'BUY'],
                mode='classification'
            )
            
            # LIME aÃ§Ä±klamasÄ±
            explanation = explainer.explain_instance(
                features[0],
                model.predict_proba,
                num_features=len(self.feature_names)
            )
            
            # SonuÃ§larÄ± parse et
            lime_result = {
                'explanation': explanation.as_list(),
                'score': explanation.score,
                'prediction': explanation.prediction
            }
            
            logger.info(f"âœ… LIME explanation completed")
            return lime_result
            
        except Exception as e:
            logger.error(f"âŒ LIME explanation error: {e}")
            return {}
    
    def generate_decision_factors(self, feature_importance: Dict[str, float], data: Dict[str, float]) -> List[str]:
        """Karar faktÃ¶rlerini oluÅŸtur"""
        try:
            factors = []
            
            # En Ã¶nemli feature'larÄ± sÄ±rala
            sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
            
            for feature_name, importance in sorted_features[:5]:  # Top 5
                if importance > 0.1:  # Minimum threshold
                    value = data.get(feature_name, 0)
                    description = self.feature_descriptions.get(feature_name, feature_name)
                    
                    # DeÄŸere gÃ¶re aÃ§Ä±klama oluÅŸtur
                    if feature_name == 'rsi':
                        if value > 70:
                            factor = f"RSI aÅŸÄ±rÄ± alÄ±m bÃ¶lgesinde ({value:.1f}) - SatÄ±ÅŸ baskÄ±sÄ±"
                        elif value < 30:
                            factor = f"RSI aÅŸÄ±rÄ± satÄ±m bÃ¶lgesinde ({value:.1f}) - AlÄ±m fÄ±rsatÄ±"
                        else:
                            factor = f"RSI normal seviyede ({value:.1f})"
                    elif feature_name == 'macd':
                        if value > 0:
                            factor = f"MACD pozitif ({value:.3f}) - YÃ¼kseliÅŸ momentumu"
                        else:
                            factor = f"MACD negatif ({value:.3f}) - DÃ¼ÅŸÃ¼ÅŸ momentumu"
                    elif feature_name == 'volume_ratio':
                        if value > 1.5:
                            factor = f"YÃ¼ksek hacim ({value:.1f}x) - GÃ¼Ã§lÃ¼ hareket"
                        elif value < 0.5:
                            factor = f"DÃ¼ÅŸÃ¼k hacim ({value:.1f}x) - ZayÄ±f hareket"
                        else:
                            factor = f"Normal hacim ({value:.1f}x)"
                    else:
                        factor = f"{description}: {value:.2f}"
                    
                    factors.append(factor)
            
            return factors
            
        except Exception as e:
            logger.error(f"âŒ Generate decision factors error: {e}")
            return ["AÃ§Ä±klama oluÅŸturulamadÄ±"]
    
    async def explain_prediction(self, 
                                symbol: str,
                                model_path: str,
                                model_type: str,
                                data: Dict[str, float],
                                prediction: str,
                                confidence: float) -> ExplanationResult:
        """Tahmin aÃ§Ä±klamasÄ± oluÅŸtur"""
        try:
            # Cache kontrolÃ¼
            cache_key = f"{symbol}_{model_path}_{hash(str(data))}"
            if cache_key in self.explanation_cache:
                logger.info(f"ğŸ“‹ Using cached explanation for {symbol}")
                return self.explanation_cache[cache_key]
            
            # Modeli yÃ¼kle
            if not self.load_model(model_type, model_path):
                raise Exception(f"Model could not be loaded: {model_path}")
            
            model = self.loaded_models[model_path]
            
            # Feature'larÄ± hazÄ±rla
            features = self.prepare_features(data)
            
            # SHAP aÃ§Ä±klamasÄ±
            shap_importance = self.explain_with_shap(model, features, model_type)
            
            # LIME aÃ§Ä±klamasÄ±
            lime_explanation = self.explain_with_lime(model, features, model_type)
            
            # Karar faktÃ¶rlerini oluÅŸtur
            decision_factors = self.generate_decision_factors(shap_importance, data)
            
            # SonuÃ§ oluÅŸtur
            explanation = ExplanationResult(
                symbol=symbol,
                prediction=prediction,
                confidence=confidence,
                shap_values=shap_importance,
                lime_explanation=lime_explanation,
                feature_importance=shap_importance,
                decision_factors=decision_factors,
                timestamp=datetime.now()
            )
            
            # Cache'e ekle
            self.explanation_cache[cache_key] = explanation
            
            logger.info(f"âœ… Explanation generated for {symbol}")
            return explanation
            
        except Exception as e:
            logger.error(f"âŒ Explain prediction error: {e}")
            # Fallback explanation
            return ExplanationResult(
                symbol=symbol,
                prediction=prediction,
                confidence=confidence,
                shap_values={},
                lime_explanation={},
                feature_importance={},
                decision_factors=["AÃ§Ä±klama oluÅŸturulamadÄ±"],
                timestamp=datetime.now()
            )
    
    def get_feature_explanations(self, explanation: ExplanationResult) -> List[FeatureExplanation]:
        """Feature aÃ§Ä±klamalarÄ±nÄ± getir"""
        try:
            explanations = []
            
            for feature_name, importance in explanation.feature_importance.items():
                if importance > 0.05:  # Minimum threshold
                    description = self.feature_descriptions.get(feature_name, feature_name)
                    
                    explanations.append(FeatureExplanation(
                        feature_name=feature_name,
                        feature_value=0,  # Bu deÄŸer data'dan alÄ±nmalÄ±
                        importance_score=importance,
                        contribution=importance * 100,
                        explanation=description
                    ))
            
            # Ã–nem sÄ±rasÄ±na gÃ¶re sÄ±rala
            explanations.sort(key=lambda x: x.importance_score, reverse=True)
            
            return explanations
            
        except Exception as e:
            logger.error(f"âŒ Get feature explanations error: {e}")
            return []
    
    def generate_summary_explanation(self, explanation: ExplanationResult) -> str:
        """Ã–zet aÃ§Ä±klama oluÅŸtur"""
        try:
            symbol = explanation.symbol
            prediction = explanation.prediction
            confidence = explanation.confidence
            
            # Ana faktÃ¶rleri al
            top_factors = explanation.decision_factors[:3]
            
            summary = f"ğŸ“Š {symbol} iÃ§in {prediction} sinyali (%{confidence:.1f} gÃ¼ven):\n\n"
            
            for i, factor in enumerate(top_factors, 1):
                summary += f"{i}. {factor}\n"
            
            # SHAP Ã¶zeti
            if explanation.shap_values:
                top_feature = max(explanation.shap_values.items(), key=lambda x: x[1])
                summary += f"\nğŸ” En etkili faktÃ¶r: {self.feature_descriptions.get(top_feature[0], top_feature[0])}"
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ Generate summary explanation error: {e}")
            return f"ğŸ“Š {explanation.symbol} iÃ§in {explanation.prediction} sinyali (%{explanation.confidence:.1f} gÃ¼ven)"
    
    def get_explanation_statistics(self) -> Dict[str, Any]:
        """AÃ§Ä±klama istatistiklerini getir"""
        try:
            stats = {
                'total_explanations': len(self.explanation_cache),
                'models_loaded': len(self.loaded_models),
                'features_available': len(self.feature_names),
                'shap_available': SHAP_AVAILABLE,
                'lime_available': LIME_AVAILABLE,
                'cache_hit_rate': 0,  # Bu hesaplanabilir
                'average_explanation_time': 0  # Bu hesaplanabilir
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ Get explanation statistics error: {e}")
            return {}
    
    def clear_cache(self):
        """Cache'i temizle"""
        try:
            self.explanation_cache.clear()
            logger.info("ğŸ§¹ Explanation cache cleared")
            
        except Exception as e:
            logger.error(f"âŒ Clear cache error: {e}")

# Global instance
xai_explain_engine = XAIExplainEngine()

if __name__ == "__main__":
    async def test_xai():
        """Test fonksiyonu"""
        logger.info("ğŸ§ª Testing XAI Explain Engine...")
        
        # Test verisi
        test_data = {
            'close_price': 245.50,
            'sma_20': 240.30,
            'sma_50': 235.80,
            'ema_12': 243.20,
            'ema_26': 238.90,
            'macd': 4.30,
            'macd_signal': 2.10,
            'rsi': 65.5,
            'bb_upper': 250.20,
            'bb_middle': 240.10,
            'bb_lower': 230.00,
            'volume_ratio': 1.8,
            'price_change': 2.3,
            'volume_change': 15.2,
            'volatility': 0.12
        }
        
        # Test aÃ§Ä±klama
        explanation = await xai_explain_engine.explain_prediction(
            symbol="THYAO",
            model_path="test_model.pkl",
            model_type="tree",
            data=test_data,
            prediction="BUY",
            confidence=0.87
        )
        
        logger.info(f"âœ… Test explanation: {explanation.decision_factors}")
        
        # Ã–zet aÃ§Ä±klama
        summary = xai_explain_engine.generate_summary_explanation(explanation)
        logger.info(f"ğŸ“Š Summary: {summary}")
        
        logger.info("âœ… XAI Explain Engine test completed")
    
    # Test Ã§alÄ±ÅŸtÄ±r
    asyncio.run(test_xai())