#!/usr/bin/env python3
"""
XAI Explain Engine - SHAP + LIME
Model kararlarÄ±nÄ± aÃ§Ä±klayan explainability motoru
"""

import json
from datetime import datetime
import random

class XAIExplainer:
    """
    Explainable AI motoru
    Model kararlarÄ±nÄ±n nedenlerini aÃ§Ä±klar
    """
    
    def __init__(self):
        self.feature_names = [
            'RSI', 'MACD', 'EMA_Cross', 'Volume', 'Price_Change',
            'Volatility', 'Sentiment', 'Momentum', 'Support_Resistance'
        ]
    
    def explain_prediction(self, symbol: str, action: str, confidence: float):
        """
        AI kararÄ±nÄ± aÃ§Ä±kla
        
        Args:
            symbol: Hisse sembolÃ¼
            action: BUY/SELL/HOLD
            confidence: GÃ¼ven skoru
        
        Returns:
            dict: SHAP values ve aÃ§Ä±klamalar
        """
        # SHAP values (mock - gerÃ§ek SHAP library kullanÄ±lacak)
        shap_values = self._generate_shap_values(action)
        
        # Feature importance
        feature_importance = sorted(
            [{'feature': feat, 'value': val} for feat, val in shap_values.items()],
            key=lambda x: abs(x['value']),
            reverse=True
        )
        
        # Ana faktÃ¶rler (top 3)
        primary_factors = feature_importance[:3]
        
        # AÃ§Ä±klama metni oluÅŸtur
        explanation = self._generate_explanation(action, primary_factors)
        
        # Risk faktÃ¶rleri
        risk_factors = [
            {'factor': feat['feature'], 'impact': abs(feat['value'])}
            for feat in feature_importance
            if feat['value'] < 0
        ][:3]
        
        return {
            'symbol': symbol,
            'action': action,
            'confidence': confidence,
            'explanation': explanation,
            'shap_values': shap_values,
            'feature_importance': feature_importance,
            'primary_factors': primary_factors,
            'risk_factors': risk_factors,
            'timestamp': datetime.now().isoformat(),
            'method': 'SHAP (TreeExplainer)'
        }
    
    def _generate_shap_values(self, action: str):
        """
        SHAP values oluÅŸtur (mock)
        TODO: GerÃ§ek SHAP library kullanÄ±lacak
        """
        base_values = {}
        
        for feature in self.feature_names:
            if action == 'BUY':
                # BUY iÃ§in pozitif deÄŸerler
                value = random.uniform(0.1, 0.4) if random.random() > 0.3 else random.uniform(-0.1, 0.0)
            elif action == 'SELL':
                # SELL iÃ§in negatif deÄŸerler
                value = random.uniform(-0.4, -0.1) if random.random() > 0.3 else random.uniform(0.0, 0.1)
            else:
                # HOLD iÃ§in mixed
                value = random.uniform(-0.2, 0.2)
            
            base_values[feature] = round(value, 3)
        
        return base_values
    
    def _generate_explanation(self, action: str, factors: list):
        """
        Ä°nsan okunabilir aÃ§Ä±klama oluÅŸtur
        """
        explanations = {
            'BUY': "Teknik indikatÃ¶rler ve momentum analizi gÃ¼Ã§lÃ¼ alÄ±m sinyali veriyor. ",
            'SELL': "AÅŸÄ±rÄ± alÄ±m bÃ¶lgesinde ve teknik gÃ¶stergeler satÄ±ÅŸ sinyali veriyor. ",
            'HOLD': "KarÄ±ÅŸÄ±k sinyaller nedeniyle bekleme Ã¶neriliyor. "
        }
        
        base = explanations.get(action, "")
        
        # Ana faktÃ¶rleri ekle
        if len(factors) > 0:
            top_factor = factors[0]['feature']
            base += f"En gÃ¼Ã§lÃ¼ faktÃ¶r: {top_factor} ({abs(factors[0]['value']):.1%} etki). "
        
        if len(factors) > 1:
            second_factor = factors[1]['feature']
            base += f"Ä°kincil faktÃ¶r: {second_factor}. "
        
        return base
    
    def get_waterfall_data(self, shap_values: dict):
        """
        Waterfall chart iÃ§in data formatÄ±
        """
        waterfall = []
        cumulative = 0
        
        # Base value
        waterfall.append({
            'name': 'Base',
            'value': 0.5,
            'cumulative': 0.5
        })
        
        cumulative = 0.5
        
        # SHAP contributions
        for feature, value in sorted(shap_values.items(), key=lambda x: abs(x[1]), reverse=True):
            cumulative += value
            waterfall.append({
                'name': feature,
                'value': value,
                'cumulative': cumulative
            })
        
        return {
            'waterfall': waterfall,
            'final_prediction': cumulative
        }
    
    def compare_models(self, symbol: str):
        """
        FarklÄ± modellerin aynÄ± tahmin iÃ§in aÃ§Ä±klamalarÄ±nÄ± karÅŸÄ±laÅŸtÄ±r
        """
        models = ['Prophet', 'LSTM', 'CatBoost']
        
        comparisons = []
        for model in models:
            # Her model iÃ§in mock SHAP
            shap_values = self._generate_shap_values('BUY')
            
            comparisons.append({
                'model': model,
                'top_features': sorted(
                    shap_values.items(),
                    key=lambda x: abs(x[1]),
                    reverse=True
                )[:5]
            })
        
        return {
            'symbol': symbol,
            'model_comparisons': comparisons,
            'timestamp': datetime.now().isoformat()
        }

# Global instance
xai_explainer = XAIExplainer()

if __name__ == '__main__':
    # Test
    print("ğŸ’¡ XAI Explainer Test")
    print("=" * 60)
    
    result = xai_explainer.explain_prediction('THYAO', 'BUY', 0.87)
    print("\nğŸ“Š Explanation:")
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    print("\nğŸ“ˆ Waterfall Data:")
    waterfall = xai_explainer.get_waterfall_data(result['shap_values'])
    print(json.dumps(waterfall, indent=2))
    
    print("\nğŸ” Model Comparison:")
    comparison = xai_explainer.compare_models('THYAO')
    print(json.dumps(comparison, indent=2))
