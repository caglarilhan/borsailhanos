"""
XAI (Explainable AI) Sistemi
Sinyal aÃ§Ä±klamasÄ± iÃ§in SHAP ve LIME entegrasyonu
"""

import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
import logging
from dataclasses import dataclass
import os

# XAI kÃ¼tÃ¼phaneleri
try:
    import shap
    import lime
    from lime.lime_tabular import LimeTabularExplainer
    SHAP_AVAILABLE = True
    LIME_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False
    LIME_AVAILABLE = False
    logger.warning("âš ï¸ SHAP veya LIME kÃ¼tÃ¼phaneleri yÃ¼klÃ¼ deÄŸil. XAI Ã¶zellikleri devre dÄ±ÅŸÄ±.")

logger = logging.getLogger(__name__)

@dataclass
class XAIExplanation:
    """XAI aÃ§Ä±klama sonucu"""
    symbol: str
    timeframe: str
    signal_action: str
    confidence: float
    explanation_method: str
    feature_contributions: Dict[str, float]
    explanation_text: str
    explanation_date: datetime
    model_type: str

class XAIExplainer:
    """XAI AÃ§Ä±klayÄ±cÄ±"""
    
    def __init__(self, data_dir: str = "data/xai"):
        self.data_dir = data_dir
        self.explanations: Dict[str, XAIExplanation] = {}
        
        # XAI dosyalarÄ±nÄ± oluÅŸtur
        os.makedirs(data_dir, exist_ok=True)
        
        # SHAP ve LIME durumunu kontrol et
        if not SHAP_AVAILABLE:
            logger.warning("âš ï¸ SHAP kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil. SHAP aÃ§Ä±klamalarÄ± devre dÄ±ÅŸÄ±.")
        if not LIME_AVAILABLE:
            logger.warning("âš ï¸ LIME kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil. LIME aÃ§Ä±klamalarÄ± devre dÄ±ÅŸÄ±.")
    
    def explain_signal(self, symbol: str, timeframe: str, 
                      signal_data: Dict, model_data: Dict, 
                      method: str = "both") -> XAIExplanation:
        """Sinyal aÃ§Ä±klamasÄ± oluÅŸtur"""
        try:
            logger.info(f"ğŸ” {symbol} {timeframe} iÃ§in XAI aÃ§Ä±klamasÄ± oluÅŸturuluyor...")
            
            if method == "shap" and SHAP_AVAILABLE:
                explanation = self._explain_with_shap(symbol, timeframe, signal_data, model_data)
            elif method == "lime" and LIME_AVAILABLE:
                explanation = self._explain_with_lime(symbol, timeframe, signal_data, model_data)
            elif method == "both":
                # Her iki yÃ¶ntemi de dene
                if SHAP_AVAILABLE:
                    explanation = self._explain_with_shap(symbol, timeframe, signal_data, model_data)
                elif LIME_AVAILABLE:
                    explanation = self._explain_with_lime(symbol, timeframe, signal_data, model_data)
                else:
                    explanation = self._explain_with_simple(symbol, timeframe, signal_data, model_data)
            else:
                explanation = self._explain_with_simple(symbol, timeframe, signal_data, model_data)
            
            if explanation:
                # Sonucu kaydet
                self.explanations[f"{symbol}_{timeframe}"] = explanation
                self._save_explanation(explanation)
                
                logger.info(f"âœ… {symbol} {timeframe} XAI aÃ§Ä±klamasÄ± tamamlandÄ±")
                return explanation
            else:
                logger.warning(f"âš ï¸ {symbol} {timeframe} XAI aÃ§Ä±klamasÄ± oluÅŸturulamadÄ±")
                return None
                
        except Exception as e:
            logger.error(f"âŒ XAI aÃ§Ä±klama hatasÄ± {symbol} {timeframe}: {e}")
            return None
    
    def _explain_with_shap(self, symbol: str, timeframe: str, 
                          signal_data: Dict, model_data: Dict) -> XAIExplanation:
        """SHAP ile aÃ§Ä±klama oluÅŸtur"""
        try:
            if not SHAP_AVAILABLE:
                return None
            
            # Model ve veri hazÄ±rla
            model = model_data.get('model')
            features = model_data.get('features')
            feature_names = model_data.get('feature_names', [])
            
            if model is None or features is None:
                logger.warning(f"âš ï¸ {symbol} {timeframe}: Model veya features bulunamadÄ±")
                return None
            
            # SHAP explainer oluÅŸtur
            if hasattr(model, 'predict_proba'):
                # SÄ±nÄ±flandÄ±rma modeli
                explainer = shap.TreeExplainer(model)
                shap_values = explainer.shap_values(features)
                
                # En son Ã¶rnek iÃ§in SHAP deÄŸerleri
                if len(shap_values.shape) > 2:
                    shap_values = shap_values[1]  # Pozitif sÄ±nÄ±f iÃ§in
                
                last_shap_values = shap_values[-1]
                
            else:
                # Regresyon modeli
                explainer = shap.TreeExplainer(model)
                shap_values = explainer.shap_values(features)
                last_shap_values = shap_values[-1]
            
            # Feature katkÄ±larÄ±nÄ± hesapla
            feature_contributions = {}
            for i, feature_name in enumerate(feature_names):
                if i < len(last_shap_values):
                    feature_contributions[feature_name] = float(last_shap_values[i])
            
            # AÃ§Ä±klama metni oluÅŸtur
            explanation_text = self._generate_shap_explanation_text(
                signal_data, feature_contributions
            )
            
            return XAIExplanation(
                symbol=symbol,
                timeframe=timeframe,
                signal_action=signal_data.get('action', 'UNKNOWN'),
                confidence=signal_data.get('confidence', 0.0),
                explanation_method="SHAP",
                feature_contributions=feature_contributions,
                explanation_text=explanation_text,
                explanation_date=datetime.now(),
                model_type=type(model).__name__
            )
            
        except Exception as e:
            logger.error(f"âŒ SHAP aÃ§Ä±klama hatasÄ±: {e}")
            return None
    
    def _explain_with_lime(self, symbol: str, timeframe: str, 
                          signal_data: Dict, model_data: Dict) -> XAIExplanation:
        """LIME ile aÃ§Ä±klama oluÅŸtur"""
        try:
            if not LIME_AVAILABLE:
                return None
            
            # Model ve veri hazÄ±rla
            model = model_data.get('model')
            features = model_data.get('features')
            feature_names = model_data.get('feature_names', [])
            
            if model is None or features is None:
                logger.warning(f"âš ï¸ {symbol} {timeframe}: Model veya features bulunamadÄ±")
                return None
            
            # LIME explainer oluÅŸtur
            explainer = LimeTabularExplainer(
                features,
                feature_names=feature_names,
                mode='classification' if hasattr(model, 'predict_proba') else 'regression',
                discretize_continuous=True
            )
            
            # En son Ã¶rnek iÃ§in aÃ§Ä±klama
            last_instance = features[-1]
            
            # LIME aÃ§Ä±klamasÄ± oluÅŸtur
            explanation = explainer.explain_instance(
                last_instance,
                model.predict_proba if hasattr(model, 'predict_proba') else model.predict,
                num_features=min(10, len(feature_names))
            )
            
            # Feature katkÄ±larÄ±nÄ± al
            feature_contributions = {}
            for feature_idx, contribution in explanation.as_list():
                feature_contributions[feature_idx] = contribution
            
            # AÃ§Ä±klama metni oluÅŸtur
            explanation_text = self._generate_lime_explanation_text(
                signal_data, feature_contributions
            )
            
            return XAIExplanation(
                symbol=symbol,
                timeframe=timeframe,
                signal_action=signal_data.get('action', 'UNKNOWN'),
                confidence=signal_data.get('confidence', 0.0),
                explanation_method="LIME",
                feature_contributions=feature_contributions,
                explanation_text=explanation_text,
                explanation_date=datetime.now(),
                model_type=type(model).__name__
            )
            
        except Exception as e:
            logger.error(f"âŒ LIME aÃ§Ä±klama hatasÄ±: {e}")
            return None
    
    def _explain_with_simple(self, symbol: str, timeframe: str, 
                           signal_data: Dict, model_data: Dict) -> XAIExplanation:
        """Basit aÃ§Ä±klama oluÅŸtur (SHAP/LIME yoksa)"""
        try:
            # Basit feature analizi
            feature_contributions = {}
            
            # Teknik indikatÃ¶rlerden katkÄ± hesapla
            indicators = signal_data.get('indicators', {})
            
            for indicator_name, value in indicators.items():
                if isinstance(value, (int, float)) and not np.isnan(value):
                    # Basit katkÄ± hesaplama
                    if indicator_name in ['RSI', 'MACD', 'EMA_9', 'EMA_21']:
                        feature_contributions[indicator_name] = float(value) * 0.1
                    elif indicator_name in ['Volume_Ratio', 'VWAP']:
                        feature_contributions[indicator_name] = float(value) * 0.05
                    else:
                        feature_contributions[indicator_name] = float(value) * 0.02
            
            # AÃ§Ä±klama metni oluÅŸtur
            explanation_text = self._generate_simple_explanation_text(
                signal_data, feature_contributions
            )
            
            return XAIExplanation(
                symbol=symbol,
                timeframe=timeframe,
                signal_action=signal_data.get('action', 'UNKNOWN'),
                confidence=signal_data.get('confidence', 0.0),
                explanation_method="SIMPLE",
                feature_contributions=feature_contributions,
                explanation_text=explanation_text,
                explanation_date=datetime.now(),
                model_type="Simple"
            )
            
        except Exception as e:
            logger.error(f"âŒ Basit aÃ§Ä±klama hatasÄ±: {e}")
            return None
    
    def _generate_shap_explanation_text(self, signal_data: Dict, 
                                      feature_contributions: Dict[str, float]) -> str:
        """SHAP aÃ§Ä±klama metni oluÅŸtur"""
        try:
            action = signal_data.get('action', 'UNKNOWN')
            confidence = signal_data.get('confidence', 0.0)
            
            # En Ã¶nemli feature'larÄ± bul
            sorted_features = sorted(
                feature_contributions.items(), 
                key=lambda x: abs(x[1]), 
                reverse=True
            )[:5]
            
            explanation_parts = [
                f"ğŸ§  {action} sinyali iÃ§in XAI aÃ§Ä±klamasÄ± (SHAP):",
                f"ğŸ“Š GÃ¼ven Skoru: {confidence:.3f}",
                "",
                "ğŸ” En Ã–nemli FaktÃ¶rler:"
            ]
            
            for feature_name, contribution in sorted_features:
                direction = "pozitif" if contribution > 0 else "negatif"
                impact = "artÄ±rÄ±yor" if contribution > 0 else "azaltÄ±yor"
                explanation_parts.append(
                    f"   â€¢ {feature_name}: {contribution:.3f} ({direction} etki, gÃ¼veni {impact})"
                )
            
            # Genel aÃ§Ä±klama
            explanation_parts.extend([
                "",
                "ğŸ“ˆ Sinyal MantÄ±ÄŸÄ±:",
                f"   Bu sinyal, {len(feature_contributions)} farklÄ± teknik indikatÃ¶rÃ¼n",
                f"   analizi sonucunda {confidence:.1%} gÃ¼venle Ã¼retilmiÅŸtir.",
                "   SHAP deÄŸerleri, her indikatÃ¶rÃ¼n sinyal kararÄ±na katkÄ±sÄ±nÄ± gÃ¶sterir."
            ])
            
            return "\n".join(explanation_parts)
            
        except Exception as e:
            logger.error(f"âŒ SHAP aÃ§Ä±klama metni hatasÄ±: {e}")
            return f"âŒ AÃ§Ä±klama metni oluÅŸturulamadÄ±: {e}"
    
    def _generate_lime_explanation_text(self, signal_data: Dict, 
                                      feature_contributions: Dict[str, float]) -> str:
        """LIME aÃ§Ä±klama metni oluÅŸtur"""
        try:
            action = signal_data.get('action', 'UNKNOWN')
            confidence = signal_data.get('confidence', 0.0)
            
            # En Ã¶nemli feature'larÄ± bul
            sorted_features = sorted(
                feature_contributions.items(), 
                key=lambda x: abs(x[1]), 
                reverse=True
            )[:5]
            
            explanation_parts = [
                f"ğŸ§  {action} sinyali iÃ§in XAI aÃ§Ä±klamasÄ± (LIME):",
                f"ğŸ“Š GÃ¼ven Skoru: {confidence:.3f}",
                "",
                "ğŸ” En Ã–nemli FaktÃ¶rler:"
            ]
            
            for feature_name, contribution in sorted_features:
                direction = "pozitif" if contribution > 0 else "negatif"
                impact = "artÄ±rÄ±yor" if contribution > 0 else "azaltÄ±yor"
                explanation_parts.append(
                    f"   â€¢ {feature_name}: {contribution:.3f} ({direction} etki, gÃ¼veni {impact})"
                )
            
            # Genel aÃ§Ä±klama
            explanation_parts.extend([
                "",
                "ğŸ“ˆ Sinyal MantÄ±ÄŸÄ±:",
                f"   Bu sinyal, {len(feature_contributions)} farklÄ± teknik indikatÃ¶rÃ¼n",
                f"   analizi sonucunda {confidence:.1%} gÃ¼venle Ã¼retilmiÅŸtir.",
                "   LIME deÄŸerleri, yerel aÃ§Ä±klanabilirlik saÄŸlar."
            ])
            
            return "\n".join(explanation_parts)
            
        except Exception as e:
            logger.error(f"âŒ LIME aÃ§Ä±klama metni hatasÄ±: {e}")
            return f"âŒ AÃ§Ä±klama metni oluÅŸturulamadÄ±: {e}"
    
    def _generate_simple_explanation_text(self, signal_data: Dict, 
                                        feature_contributions: Dict[str, float]) -> str:
        """Basit aÃ§Ä±klama metni oluÅŸtur"""
        try:
            action = signal_data.get('action', 'UNKNOWN')
            confidence = signal_data.get('confidence', 0.0)
            
            # En Ã¶nemli feature'larÄ± bul
            sorted_features = sorted(
                feature_contributions.items(), 
                key=lambda x: abs(x[1]), 
                reverse=True
            )[:5]
            
            explanation_parts = [
                f"ğŸ§  {action} sinyali iÃ§in basit aÃ§Ä±klama:",
                f"ğŸ“Š GÃ¼ven Skoru: {confidence:.3f}",
                "",
                "ğŸ” En Ã–nemli FaktÃ¶rler:"
            ]
            
            for feature_name, contribution in sorted_features:
                direction = "pozitif" if contribution > 0 else "negatif"
                impact = "artÄ±rÄ±yor" if contribution > 0 else "azaltÄ±yor"
                explanation_parts.append(
                    f"   â€¢ {feature_name}: {contribution:.3f} ({direction} etki, gÃ¼veni {impact})"
                )
            
            # Genel aÃ§Ä±klama
            explanation_parts.extend([
                "",
                "ğŸ“ˆ Sinyal MantÄ±ÄŸÄ±:",
                f"   Bu sinyal, {len(feature_contributions)} farklÄ± teknik indikatÃ¶rÃ¼n",
                f"   analizi sonucunda {confidence:.1%} gÃ¼venle Ã¼retilmiÅŸtir.",
                "   Basit analiz yÃ¶ntemi kullanÄ±lmÄ±ÅŸtÄ±r."
            ])
            
            return "\n".join(explanation_parts)
            
        except Exception as e:
            logger.error(f"âŒ Basit aÃ§Ä±klama metni hatasÄ±: {e}")
            return f"âŒ AÃ§Ä±klama metni oluÅŸturulamadÄ±: {e}"
    
    def _save_explanation(self, explanation: XAIExplanation):
        """AÃ§Ä±klamayÄ± kaydet"""
        try:
            filename = f"{explanation.symbol}_{explanation.timeframe}_xai.json"
            filepath = os.path.join(self.data_dir, filename)
            
            # JSON olarak kaydet
            import json
            explanation_dict = {
                'symbol': explanation.symbol,
                'timeframe': explanation.timeframe,
                'signal_action': explanation.signal_action,
                'confidence': explanation.confidence,
                'explanation_method': explanation.explanation_method,
                'feature_contributions': explanation.feature_contributions,
                'explanation_text': explanation.explanation_text,
                'explanation_date': explanation.explanation_date.isoformat(),
                'model_type': explanation.model_type
            }
            
            with open(filepath, 'w') as f:
                json.dump(explanation_dict, f, indent=2)
            
            logger.info(f"âœ… XAI aÃ§Ä±klamasÄ± kaydedildi: {filepath}")
            
        except Exception as e:
            logger.error(f"âŒ XAI kaydetme hatasÄ±: {e}")
    
    def get_explanation(self, symbol: str, timeframe: str) -> Optional[XAIExplanation]:
        """AÃ§Ä±klamayÄ± al"""
        try:
            return self.explanations.get(f"{symbol}_{timeframe}")
        except Exception as e:
            logger.error(f"âŒ AÃ§Ä±klama alma hatasÄ±: {e}")
            return None
    
    def generate_explanation_summary(self, symbol: str, timeframe: str) -> str:
        """AÃ§Ä±klama Ã¶zeti oluÅŸtur"""
        try:
            explanation = self.get_explanation(symbol, timeframe)
            
            if not explanation:
                return f"âŒ {symbol} {timeframe} iÃ§in aÃ§Ä±klama bulunamadÄ±"
            
            return explanation.explanation_text
            
        except Exception as e:
            logger.error(f"âŒ AÃ§Ä±klama Ã¶zeti hatasÄ±: {e}")
            return f"âŒ AÃ§Ä±klama Ã¶zeti oluÅŸturulamadÄ±: {e}"
