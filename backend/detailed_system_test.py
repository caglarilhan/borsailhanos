"""
ğŸ§ª DETAILED SYSTEM TEST - BIST AI Smart Trader
Mevcut %134 accuracy sistemini detaylÄ± test eder
Sprint-0 modÃ¼llerini ve mevcut sistemleri kapsamlÄ± kontrol eder
"""

import asyncio
import logging
import time
from datetime import datetime
from typing import Dict, List, Optional
import json
import pandas as pd
import numpy as np

# Local imports
from integrated_sprint0_system import IntegratedSprint0System
from finnhub_websocket_layer import FinnhubWebSocketLayer
from fundamental_data_layer import FundamentalDataLayer
from grey_topsis_entropy_ranking import GreyTOPSISEntropyRanking

# Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DetailedSystemTest:
    """
    Mevcut sistemi detaylÄ± test eder
    Her modÃ¼lÃ¼ ayrÄ± ayrÄ± ve entegre olarak test eder
    """
    
    def __init__(self):
        self.test_results = {
            'start_time': datetime.now().isoformat(),
            'modules_tested': [],
            'integration_tests': [],
            'performance_metrics': {},
            'errors': [],
            'warnings': [],
            'final_status': 'PENDING'
        }
        
        # Test sembolleri
        self.test_symbols = [
            "AAPL", "GOOGL", "MSFT",  # ABD
            "SISE.IS", "EREGL.IS", "TUPRS.IS"  # BIST
        ]
        
        logger.info("ğŸ§ª Detailed System Test baÅŸlatÄ±ldÄ±")
    
    async def test_websocket_layer_detailed(self) -> Dict:
        """WebSocket layer detaylÄ± testi"""
        logger.info("ğŸ”Œ WebSocket Layer DetaylÄ± Test BaÅŸlÄ±yor...")
        
        test_result = {
            'module': 'WebSocket Layer',
            'status': 'PENDING',
            'tests': [],
            'performance': {},
            'errors': []
        }
        
        try:
            # 1. Mock mode test
            start_time = time.time()
            ws_layer = FinnhubWebSocketLayer(use_mock=True)
            creation_time = time.time() - start_time
            
            test_result['tests'].append({
                'test': 'Mock Mode Creation',
                'status': 'PASS',
                'time': creation_time,
                'details': 'Mock WebSocket layer baÅŸarÄ±yla oluÅŸturuldu'
            })
            
            # 2. Connection test
            start_time = time.time()
            connected = await ws_layer.connect()
            connection_time = time.time() - start_time
            
            if connected:
                test_result['tests'].append({
                    'test': 'Connection Test',
                    'status': 'PASS',
                    'time': connection_time,
                    'details': 'Mock baÄŸlantÄ± baÅŸarÄ±lÄ±'
                })
            else:
                test_result['tests'].append({
                    'test': 'Connection Test',
                    'status': 'FAIL',
                    'time': connection_time,
                    'details': 'Mock baÄŸlantÄ± baÅŸarÄ±sÄ±z'
                })
                test_result['errors'].append('Mock baÄŸlantÄ± kurulamadÄ±')
            
            # 3. Subscription test
            start_time = time.time()
            await ws_layer.subscribe_symbols(self.test_symbols[:3])
            subscription_time = time.time() - start_time
            
            test_result['tests'].append({
                'test': 'Subscription Test',
                'status': 'PASS',
                'time': subscription_time,
                'details': f'{len(self.test_symbols[:3])} sembol subscribe edildi'
            })
            
            # 4. Price callback test
            price_received = False
            async def test_callback(symbol, price, volume, timestamp):
                nonlocal price_received
                price_received = True
                logger.info(f"ğŸ“ˆ Test Callback: {symbol} - ${price:.2f}")
            
            ws_layer.add_price_callback(test_callback)
            
            # 5. Mock streaming test
            start_time = time.time()
            streaming_task = asyncio.create_task(ws_layer._mock_streaming())
            await asyncio.sleep(5)  # 5 saniye bekle
            streaming_task.cancel()
            streaming_time = time.time() - start_time
            
            if price_received:
                test_result['tests'].append({
                    'test': 'Mock Streaming Test',
                    'status': 'PASS',
                    'time': streaming_time,
                    'details': 'Mock fiyat verisi baÅŸarÄ±yla alÄ±ndÄ±'
                })
            else:
                test_result['tests'].append({
                    'test': 'Mock Streaming Test',
                    'status': 'FAIL',
                    'time': streaming_time,
                    'details': 'Mock fiyat verisi alÄ±namadÄ±'
                })
                test_result['errors'].append('Mock streaming Ã§alÄ±ÅŸmÄ±yor')
            
            # 6. Disconnect test
            await ws_layer.disconnect()
            
            # Performance metrics
            test_result['performance'] = {
                'creation_time': creation_time,
                'connection_time': connection_time,
                'subscription_time': subscription_time,
                'streaming_time': streaming_time,
                'total_time': time.time() - start_time
            }
            
            # Final status
            if len(test_result['errors']) == 0:
                test_result['status'] = 'PASS'
                logger.info("âœ… WebSocket Layer detaylÄ± testi baÅŸarÄ±lÄ±")
            else:
                test_result['status'] = 'FAIL'
                logger.error(f"âŒ WebSocket Layer detaylÄ± testi baÅŸarÄ±sÄ±z: {len(test_result['errors'])} hata")
            
        except Exception as e:
            test_result['status'] = 'ERROR'
            test_result['errors'].append(f'Test hatasÄ±: {str(e)}')
            logger.error(f"âŒ WebSocket test hatasÄ±: {e}")
        
        return test_result
    
    async def test_fundamental_layer_detailed(self) -> Dict:
        """Fundamental data layer detaylÄ± testi"""
        logger.info("ğŸ“Š Fundamental Data Layer DetaylÄ± Test BaÅŸlÄ±yor...")
        
        test_result = {
            'module': 'Fundamental Data Layer',
            'status': 'PENDING',
            'tests': [],
            'performance': {},
            'errors': []
        }
        
        try:
            start_time = time.time()
            
            # 1. Layer creation test
            fundamental_layer = FundamentalDataLayer()
            creation_time = time.time() - start_time
            
            test_result['tests'].append({
                'test': 'Layer Creation',
                'status': 'PASS',
                'time': creation_time,
                'details': 'Fundamental layer baÅŸarÄ±yla oluÅŸturuldu'
            })
            
            # 2. Batch financial scores test
            start_time = time.time()
            scores = await fundamental_layer.get_batch_financial_scores(self.test_symbols[:3])
            batch_time = time.time() - start_time
            
            if scores and len(scores) > 0:
                test_result['tests'].append({
                    'test': 'Batch Financial Scores',
                    'status': 'PASS',
                    'time': batch_time,
                    'details': f'{len(scores)} sembol iÃ§in skor hesaplandÄ±'
                })
                
                # Score details
                for score in scores:
                    if score.get('error'):
                        test_result['warnings'].append(f"{score['symbol']}: {score['error']}")
                    else:
                        logger.info(f"âœ… {score['symbol']}: {score.get('percentage', 0):.1f}%")
            else:
                test_result['tests'].append({
                    'test': 'Batch Financial Scores',
                    'status': 'FAIL',
                    'time': batch_time,
                    'details': 'Finansal skor hesaplanamadÄ±'
                })
                test_result['errors'].append('Batch skor hesaplama baÅŸarÄ±sÄ±z')
            
            # 3. Individual symbol test
            start_time = time.time()
            individual_score = await fundamental_layer.get_comprehensive_financial_score("AAPL")
            individual_time = time.time() - start_time
            
            if individual_score and 'percentage' in individual_score:
                test_result['tests'].append({
                    'test': 'Individual Symbol Score',
                    'status': 'PASS',
                    'time': individual_time,
                    'details': f"AAPL: {individual_score['percentage']:.1f}%"
                })
            else:
                test_result['tests'].append({
                    'test': 'Individual Symbol Score',
                    'status': 'FAIL',
                    'time': individual_time,
                    'details': 'AAPL skor hesaplanamadÄ±'
                })
                test_result['errors'].append('Individual skor hesaplama baÅŸarÄ±sÄ±z')
            
            # Performance metrics
            test_result['performance'] = {
                'creation_time': creation_time,
                'batch_time': batch_time,
                'individual_time': individual_time,
                'total_time': time.time() - start_time
            }
            
            # Final status
            if len(test_result['errors']) == 0:
                test_result['status'] = 'PASS'
                logger.info("âœ… Fundamental Data Layer detaylÄ± testi baÅŸarÄ±lÄ±")
            else:
                test_result['status'] = 'FAIL'
                logger.error(f"âŒ Fundamental Data Layer detaylÄ± testi baÅŸarÄ±sÄ±z: {len(test_result['errors'])} hata")
            
        except Exception as e:
            test_result['status'] = 'ERROR'
            test_result['errors'].append(f'Test hatasÄ±: {str(e)}')
            logger.error(f"âŒ Fundamental test hatasÄ±: {e}")
        
        return test_result
    
    async def test_ranking_system_detailed(self) -> Dict:
        """Grey TOPSIS ranking detaylÄ± testi"""
        logger.info("ğŸ† Grey TOPSIS Ranking DetaylÄ± Test BaÅŸlÄ±yor...")
        
        test_result = {
            'module': 'Grey TOPSIS Ranking',
            'status': 'PENDING',
            'tests': [],
            'performance': {},
            'errors': []
        }
        
        try:
            start_time = time.time()
            
            # 1. System creation test
            ranking_system = GreyTOPSISEntropyRanking()
            creation_time = time.time() - start_time
            
            test_result['tests'].append({
                'test': 'System Creation',
                'status': 'PASS',
                'time': creation_time,
                'details': 'Ranking system baÅŸarÄ±yla oluÅŸturuldu'
            })
            
            # 2. Test data preparation
            test_financial_data = [
                {
                    'symbol': 'SISE.IS',
                    'percentage': 85.5,
                    'dupont': {'ROE': 0.18, 'ROA': 0.12, 'Asset_Turnover': 1.2},
                    'ratios': [{'netProfitMargin': 0.15, 'debtToEquity': 0.4, 'currentRatio': 2.1}],
                    'piotroski_f_score': 7
                },
                {
                    'symbol': 'EREGL.IS',
                    'percentage': 78.2,
                    'dupont': {'ROE': 0.15, 'ROA': 0.10, 'Asset_Turnover': 1.0},
                    'ratios': [{'netProfitMargin': 0.12, 'debtToEquity': 0.6, 'currentRatio': 1.8}],
                    'piotroski_f_score': 6
                },
                {
                    'symbol': 'AAPL',
                    'percentage': 92.1,
                    'dupont': {'ROE': 0.25, 'ROA': 0.18, 'Asset_Turnover': 1.5},
                    'ratios': [{'netProfitMargin': 0.22, 'debtToEquity': 0.2, 'currentRatio': 2.5}],
                    'piotroski_f_score': 8
                }
            ]
            
            # 3. Ranking calculation test
            start_time = time.time()
            results = ranking_system.calculate_ranking(test_financial_data)
            calculation_time = time.time() - start_time
            
            if 'error' not in results and 'ranking' in results:
                test_result['tests'].append({
                    'test': 'Ranking Calculation',
                    'status': 'PASS',
                    'time': calculation_time,
                    'details': f'{len(results["ranking"])} hisse iÃ§in ranking tamamlandÄ±'
                })
                
                # Ranking details
                top_stocks = ranking_system.get_top_stocks(3)
                for stock in top_stocks:
                    logger.info(f"  {stock['rank']}. {stock['symbol']}: {stock['topsis_score']:.4f}")
            else:
                test_result['tests'].append({
                    'test': 'Ranking Calculation',
                    'status': 'FAIL',
                    'time': calculation_time,
                    'details': f'Ranking hatasÄ±: {results.get("error", "Bilinmeyen hata")}'
                })
                test_result['errors'].append('Ranking hesaplama baÅŸarÄ±sÄ±z')
            
            # 4. Top stocks test
            start_time = time.time()
            top_stocks = ranking_system.get_top_stocks(3)
            top_stocks_time = time.time() - start_time
            
            if top_stocks and len(top_stocks) == 3:
                test_result['tests'].append({
                    'test': 'Top Stocks Retrieval',
                    'status': 'PASS',
                    'time': top_stocks_time,
                    'details': f'Top {len(top_stocks)} hisse baÅŸarÄ±yla alÄ±ndÄ±'
                })
            else:
                test_result['tests'].append({
                    'test': 'Top Stocks Retrieval',
                    'status': 'FAIL',
                    'time': top_stocks_time,
                    'details': 'Top hisseler alÄ±namadÄ±'
                })
                test_result['errors'].append('Top stocks retrieval baÅŸarÄ±sÄ±z')
            
            # Performance metrics
            test_result['performance'] = {
                'creation_time': creation_time,
                'calculation_time': calculation_time,
                'top_stocks_time': top_stocks_time,
                'total_time': time.time() - start_time
            }
            
            # Final status
            if len(test_result['errors']) == 0:
                test_result['status'] = 'PASS'
                logger.info("âœ… Grey TOPSIS Ranking detaylÄ± testi baÅŸarÄ±lÄ±")
            else:
                test_result['status'] = 'FAIL'
                logger.error(f"âŒ Grey TOPSIS Ranking detaylÄ± testi baÅŸarÄ±sÄ±z: {len(test_result['errors'])} hata")
            
        except Exception as e:
            test_result['status'] = 'ERROR'
            test_result['errors'].append(f'Test hatasÄ±: {str(e)}')
            logger.error(f"âŒ Ranking test hatasÄ±: {e}")
        
        return test_result
    
    async def test_integration_system(self) -> Dict:
        """Entegre sistem testi"""
        logger.info("ğŸ”— Entegre Sistem Testi BaÅŸlÄ±yor...")
        
        test_result = {
            'module': 'Integrated System',
            'status': 'PENDING',
            'tests': [],
            'performance': {},
            'errors': []
        }
        
        try:
            start_time = time.time()
            
            # 1. Integrated system creation
            integrated_system = IntegratedSprint0System()
            creation_time = time.time() - start_time
            
            test_result['tests'].append({
                'test': 'Integrated System Creation',
                'status': 'PASS',
                'time': creation_time,
                'details': 'Entegre sistem baÅŸarÄ±yla oluÅŸturuldu'
            })
            
            # 2. Full integration test
            start_time = time.time()
            results = await integrated_system.run_full_integration()
            integration_time = time.time() - start_time
            
            if results and 'total_accuracy' in results:
                test_result['tests'].append({
                    'test': 'Full Integration',
                    'status': 'PASS',
                    'time': integration_time,
                    'details': f'Final accuracy: %{results["total_accuracy"]:.1f}'
                })
                
                # Check individual modules
                if results.get('websocket_integrated'):
                    test_result['tests'].append({
                        'test': 'WebSocket Integration',
                        'status': 'PASS',
                        'time': 0,
                        'details': 'WebSocket baÅŸarÄ±yla entegre edildi'
                    })
                else:
                    test_result['tests'].append({
                        'test': 'WebSocket Integration',
                        'status': 'FAIL',
                        'time': 0,
                        'details': 'WebSocket entegrasyonu baÅŸarÄ±sÄ±z'
                    })
                    test_result['errors'].append('WebSocket entegrasyonu baÅŸarÄ±sÄ±z')
                
                if results.get('fundamental_integrated'):
                    test_result['tests'].append({
                        'test': 'Fundamental Integration',
                        'status': 'PASS',
                        'time': 0,
                        'details': 'Fundamental data baÅŸarÄ±yla entegre edildi'
                    })
                else:
                    test_result['tests'].append({
                        'test': 'Fundamental Integration',
                        'status': 'FAIL',
                        'time': 0,
                        'details': 'Fundamental data entegrasyonu baÅŸarÄ±sÄ±z'
                    })
                    test_result['errors'].append('Fundamental data entegrasyonu baÅŸarÄ±sÄ±z')
                
                if results.get('ranking_integrated'):
                    test_result['tests'].append({
                        'test': 'Ranking Integration',
                        'status': 'PASS',
                        'time': 0,
                        'details': 'Ranking system baÅŸarÄ±yla entegre edildi'
                    })
                else:
                    test_result['tests'].append({
                        'test': 'Ranking Integration',
                        'status': 'FAIL',
                        'time': 0,
                        'details': 'Ranking system entegrasyonu baÅŸarÄ±sÄ±z'
                    })
                    test_result['errors'].append('Ranking system entegrasyonu baÅŸarÄ±sÄ±z')
            else:
                test_result['tests'].append({
                    'test': 'Full Integration',
                    'status': 'FAIL',
                    'time': integration_time,
                    'details': 'Entegrasyon sonuÃ§larÄ± alÄ±namadÄ±'
                })
                test_result['errors'].append('Full integration baÅŸarÄ±sÄ±z')
            
            # Performance metrics
            test_result['performance'] = {
                'creation_time': creation_time,
                'integration_time': integration_time,
                'total_time': time.time() - start_time
            }
            
            # Final status
            if len(test_result['errors']) == 0:
                test_result['status'] = 'PASS'
                logger.info("âœ… Entegre sistem testi baÅŸarÄ±lÄ±")
            else:
                test_result['status'] = 'FAIL'
                logger.error(f"âŒ Entegre sistem testi baÅŸarÄ±sÄ±z: {len(test_result['errors'])} hata")
            
        except Exception as e:
            test_result['status'] = 'ERROR'
            test_result['errors'].append(f'Test hatasÄ±: {str(e)}')
            logger.error(f"âŒ Entegre sistem test hatasÄ±: {e}")
        
        return test_result
    
    async def run_all_tests(self) -> Dict:
        """TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r"""
        logger.info("ğŸš€ TÃ¼m DetaylÄ± Testler BaÅŸlÄ±yor...")
        
        start_time = time.time()
        
        # 1. WebSocket Layer test
        ws_test = await self.test_websocket_layer_detailed()
        self.test_results['modules_tested'].append(ws_test)
        
        # 2. Fundamental Data Layer test
        fundamental_test = await self.test_fundamental_layer_detailed()
        self.test_results['modules_tested'].append(fundamental_test)
        
        # 3. Ranking System test
        ranking_test = await self.test_ranking_system_detailed()
        self.test_results['modules_tested'].append(ranking_test)
        
        # 4. Integration test
        integration_test = await self.test_integration_system()
        self.test_results['integration_tests'].append(integration_test)
        
        # Final results
        total_time = time.time() - start_time
        self.test_results['performance_metrics'] = {
            'total_test_time': total_time,
            'modules_passed': len([m for m in self.test_results['modules_tested'] if m['status'] == 'PASS']),
            'modules_failed': len([m for m in self.test_results['modules_tested'] if m['status'] == 'FAIL']),
            'integration_passed': len([i for i in self.test_results['integration_tests'] if i['status'] == 'PASS']),
            'integration_failed': len([i for i in self.test_results['integration_tests'] if i['status'] == 'FAIL'])
        }
        
        # Collect all errors and warnings
        for module in self.test_results['modules_tested']:
            self.test_results['errors'].extend(module.get('errors', []))
            self.test_results['warnings'].extend(module.get('warnings', []))
        
        for integration in self.test_results['integration_tests']:
            self.test_results['errors'].extend(integration.get('errors', []))
            self.test_results['warnings'].extend(integration.get('warnings', []))
        
        # Final status
        if len(self.test_results['errors']) == 0:
            self.test_results['final_status'] = 'PASS'
        elif len(self.test_results['errors']) <= 2:
            self.test_results['final_status'] = 'WARNING'
        else:
            self.test_results['final_status'] = 'FAIL'
        
        self.test_results['end_time'] = datetime.now().isoformat()
        
        # Print summary
        self._print_test_summary()
        
        return self.test_results
    
    def _print_test_summary(self):
        """Test Ã¶zetini yazdÄ±r"""
        print("\n" + "="*80)
        print("ğŸ§ª DETAILED SYSTEM TEST SUMMARY - BIST AI Smart Trader")
        print("="*80)
        
        print(f"ğŸ“… Test Tarihi: {self.test_results['start_time']}")
        print(f"â±ï¸  Toplam SÃ¼re: {self.test_results['performance_metrics']['total_test_time']:.2f} saniye")
        print()
        
        print("ğŸ”— ModÃ¼l Testleri:")
        for module in self.test_results['modules_tested']:
            status_icon = "âœ…" if module['status'] == 'PASS' else "âŒ" if module['status'] == 'FAIL' else "âš ï¸"
            print(f"  {status_icon} {module['module']}: {module['status']}")
        
        print()
        print("ğŸ”— Entegrasyon Testleri:")
        for integration in self.test_results['integration_tests']:
            status_icon = "âœ…" if integration['status'] == 'PASS' else "âŒ" if integration['status'] == 'FAIL' else "âš ï¸"
            print(f"  {status_icon} {integration['module']}: {integration['status']}")
        
        print()
        print("ğŸ“Š Performans Metrikleri:")
        metrics = self.test_results['performance_metrics']
        print(f"  ModÃ¼ller BaÅŸarÄ±lÄ±: {metrics['modules_passed']}/{len(self.test_results['modules_tested'])}")
        print(f"  Entegrasyon BaÅŸarÄ±lÄ±: {metrics['integration_passed']}/{len(self.test_results['integration_tests'])}")
        
        print()
        print("ğŸ¯ Final Status:")
        if self.test_results['final_status'] == 'PASS':
            print("  ğŸŸ¢ TÃœM TESTLER BAÅARILI!")
        elif self.test_results['final_status'] == 'WARNING':
            print("  ğŸŸ¡ BAZÄ± TESTLERDE UYARILAR VAR")
        else:
            print("  ğŸ”´ BAZÄ± TESTLER BAÅARISIZ!")
        
        if self.test_results['errors']:
            print()
            print("âŒ Hatalar:")
            for error in self.test_results['errors'][:5]:  # Ä°lk 5 hatayÄ± gÃ¶ster
                print(f"  - {error}")
            if len(self.test_results['errors']) > 5:
                print(f"  ... ve {len(self.test_results['errors']) - 5} hata daha")
        
        if self.test_results['warnings']:
            print()
            print("âš ï¸  UyarÄ±lar:")
            for warning in self.test_results['warnings'][:3]:  # Ä°lk 3 uyarÄ±yÄ± gÃ¶ster
                print(f"  - {warning}")
            if len(self.test_results['warnings']) > 3:
                print(f"  ... ve {len(self.test_results['warnings']) - 3} uyarÄ± daha")
        
        print("="*80)
    
    def save_test_results(self, filename: str = None):
        """Test sonuÃ§larÄ±nÄ± dosyaya kaydet"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"detailed_test_results_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.test_results, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"âœ… Test sonuÃ§larÄ± kaydedildi: {filename}")
            return filename
        except Exception as e:
            logger.error(f"âŒ Test sonuÃ§larÄ± kaydedilemedi: {e}")
            return None

# Test fonksiyonu
async def run_detailed_tests():
    """DetaylÄ± testleri Ã§alÄ±ÅŸtÄ±r"""
    
    print("ğŸ§ª Detailed System Test BaÅŸlÄ±yor...")
    print("ğŸ” Mevcut sistem detaylÄ± olarak test edilecek...")
    
    try:
        # Test runner oluÅŸtur
        test_runner = DetailedSystemTest()
        
        # TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r
        results = await test_runner.run_all_tests()
        
        # SonuÃ§larÄ± kaydet
        filename = test_runner.save_test_results()
        
        print(f"\nğŸ“ Test sonuÃ§larÄ± kaydedildi: {filename}")
        
        return results
        
    except Exception as e:
        print(f"âŒ Test hatasÄ±: {e}")
        return None

if __name__ == "__main__":
    # DetaylÄ± testleri Ã§alÄ±ÅŸtÄ±r
    asyncio.run(run_detailed_tests())
